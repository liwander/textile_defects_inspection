{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "requests\n",
    "tqdm>=4.65.0\n",
    "torch>=2.0.0\n",
    "# torchvision>=0.14.0\n",
    "opencv-python\n",
    "numpy>=1.23.0\n",
    "timm>=0.6.13\n",
    "# tensorboard>=2.13.0\n",
    "albumentations>=1.4.0\n",
    "# segmentation-models-pytorch>=0.3.3\n",
    "scikit-learn>=1.1.0\n",
    "matplotlib>=3.5.0\n",
    "# transformers>=4.31.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U -q pip\n",
    "! pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ---\n",
    "CONFIG = {\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 2,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-3,\n",
    "    'early_stop_patience': 10,\n",
    "    'dataroot': './aitex_data/extracted',\n",
    "    'log_dir': 'runs/classification_experiment',   # –∏–∑–º–µ–Ω–∏–ª –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "    'resume': False\n",
    "}\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "# –û–±–Ω–æ–≤–∏: –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω—É–∂–Ω—ã num_classes (–Ω–µ classes)\n",
    "NUM_CLASSES = 12 + 1  # —É–∫–∞–∂–∏ —Ä–µ–∞–ª—å–Ω–æ (–æ–±—ã—á–Ω–æ ~12 –¥–ª—è –¥–µ—Ñ–µ–∫—Ç–æ–≤ –≤ AITEX)\n",
    "\n",
    "MODELS = {\n",
    "    \"beit_base_patch16_224\": lambda: timm.create_model(\n",
    "        \"beit_base_patch16_224\",\n",
    "        pretrained=True,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        in_chans=3,\n",
    "        drop_rate=0.3,          # <--- Dropout –ø–æ—Å–ª–µ MLP\n",
    "        drop_path_rate=0.1      # <--- DropPath –º–µ–∂–¥—É –±–ª–æ–∫–∞–º–∏\n",
    "    ),\n",
    "    # \"convnext_base\": lambda: timm.create_model(\n",
    "    #     \"convnext_base\",\n",
    "    #     pretrained=True,\n",
    "    #     num_classes=NUM_CLASSES,\n",
    "    #     in_chans=3,\n",
    "    #     drop_path_rate=0.1      # —Ç–æ–ª—å–∫–æ DropPath\n",
    "    # ),\n",
    "    # \"resnet\": lambda: timm.create_model(\n",
    "    #     \"resnet50\",\n",
    "    #     pretrained=True,\n",
    "    #     num_classes=NUM_CLASSES,\n",
    "    #     in_chans=3\n",
    "    #     # Dropout –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è\n",
    "    # ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def find_max_batch_size(\n",
    "#     model_fn,\n",
    "#     device='cuda',\n",
    "#     image_size=(224, 224),\n",
    "#     max_test=512,\n",
    "#     num_classes=13,\n",
    "#     step=4\n",
    "# ):\n",
    "#     print(f\"\\n=== –ü–æ–∏—Å–∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ batch_size –¥–ª—è {model_fn.__name__ if hasattr(model_fn, '__name__') else model_fn} ===\")\n",
    "#     batch_size = step\n",
    "#     last_ok = 0\n",
    "#     model = model_fn().to(device)\n",
    "#     model.eval()\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "\n",
    "#     tried = []\n",
    "#     total_attempts = (max_test // step)\n",
    "#     pbar = tqdm(total=total_attempts, desc='–ü–æ–¥–±–æ—Ä batch_size', ncols=100)\n",
    "#     while batch_size <= max_test:\n",
    "#         try:\n",
    "#             dummy = torch.randn(batch_size, 3, image_size[0], image_size[1]).to(device)\n",
    "#             with torch.no_grad():\n",
    "#                 out = model(dummy)\n",
    "#             last_ok = batch_size\n",
    "#             tried.append(batch_size)\n",
    "#             batch_size += step\n",
    "#             del dummy, out\n",
    "#             torch.cuda.empty_cache()\n",
    "#             gc.collect()\n",
    "#             pbar.update(1)\n",
    "#         except RuntimeError as e:\n",
    "#             pbar.close()\n",
    "#             if 'out of memory' in str(e):\n",
    "#                 print(f\"\\nOOM at batch_size={batch_size}. Last OK: {last_ok}\")\n",
    "#                 break\n",
    "#             else:\n",
    "#                 print(f\"\\nError at batch_size={batch_size}: {e}\")\n",
    "#                 break\n",
    "#     pbar.close()\n",
    "#     del model\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "#     print(f\"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π batch_size: {last_ok} (–¥–ª—è image_size={image_size})\")\n",
    "#     return last_ok\n",
    "\n",
    "# # –ü—Ä–∏–º–µ—Ä: –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "# for name, model_fn in MODELS.items():\n",
    "#     print(f\"\\n=== {name} ===\")\n",
    "#     max_bs = find_max_batch_size(model_fn, device='cuda', image_size=(224,224), step=8)\n",
    "#     print(f\"Max batch_size for {name}: {max_bs}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, top_k_accuracy_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "def compute_classification_metrics(y_true, y_pred, y_prob, num_classes, top_k=3):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    metrics[\"precision_macro\"] = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics[\"recall_macro\"] = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics[\"f1_macro\"] = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics[\"precision_micro\"] = precision_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    metrics[\"recall_micro\"] = recall_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    metrics[\"f1_micro\"] = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    metrics[\"confusion_matrix\"] = confusion_matrix(y_true, y_pred)\n",
    "    if y_prob is not None:\n",
    "        metrics[\"top1\"] = top_k_accuracy_score(y_true, y_prob, k=1, labels=list(range(num_classes)))\n",
    "        metrics[\"top3\"] = top_k_accuracy_score(y_true, y_prob, k=min(3, num_classes), labels=list(range(num_classes)))\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f301d04-e66c-4c9f-8de5-dbe2914a8008"
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24403371-53b2-4d52-801a-c2c8e70e884b"
   },
   "source": [
    "## download_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5f9c7e7-768c-4a28-a6df-65cfc48fb7d2",
    "outputId": "51bca206-2f9d-4a8c-e2b4-29e6207b0562"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/nexuswho/aitex-fabric-image-database\"\n",
    "output_dir = Path(\"./aitex_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "zip_path = output_dir / \"aitex.zip\"\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞\n",
    "if zip_path.exists():\n",
    "    print(f\"[INFO] –ê—Ä—Ö–∏–≤ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ø–æ –ø—É—Ç–∏: {zip_path}\")\n",
    "else:\n",
    "    print(f\"[INFO] –°–∫–∞—á–∏–≤–∞–µ–º –∞—Ä—Ö–∏–≤ –∏–∑ {url}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n",
    "                f.write(chunk)\n",
    "        print(\"[INFO] –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\")\n",
    "    else:\n",
    "        raise Exception(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: —Å—Ç–∞—Ç—É—Å {response.status_code}\")\n",
    "\n",
    "# –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞\n",
    "extract_dir = output_dir / \"extracted\"\n",
    "if not extract_dir.exists():\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"[INFO] –ê—Ä—Ö–∏–≤ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω –≤ {extract_dir}\")\n",
    "else:\n",
    "    print(f\"[INFO] –ê—Ä—Ö–∏–≤ —É–∂–µ –±—ã–ª —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω –≤ {extract_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQ7TjMBbXK_W"
   },
   "source": [
    "## remove_image_without_masks¬∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3d_pjjlXPlU",
    "outputId": "fb355904-d0a4-4519-b64d-11269c69470a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_images_without_masks(image_dir, mask_dir, image_suffix=\".png\", mask_suffix=\"_mask.png\"):\n",
    "    \"\"\"\n",
    "    –£–¥–∞–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –º–∞—Å–∫–∞.\n",
    "    \"\"\"\n",
    "    removed = 0\n",
    "    for img_name in os.listdir(image_dir):\n",
    "        if not img_name.endswith(image_suffix):\n",
    "            continue\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        mask_name = base_name + mask_suffix\n",
    "        mask_path = os.path.join(mask_dir, mask_name)\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"–£–¥–∞–ª—è–µ—Ç—Å—è {img_path} (–º–∞—Å–∫–∞ {mask_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞)\")\n",
    "            os.remove(img_path)\n",
    "            removed += 1\n",
    "    print(f\"–£–¥–∞–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –º–∞—Å–æ–∫: {removed}\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞:\n",
    "remove_images_without_masks(\n",
    "    image_dir=\"./aitex_data/extracted/Defect_images\",\n",
    "    mask_dir=\"./aitex_data/extracted/Mask_images\"\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_and_save_random_image_with_mask(\n",
    "    image_dir, mask_dir,\n",
    "    image_suffix=\".png\", mask_suffix=\"_mask.png\",\n",
    "    save_dir=\"./random_samples\"\n",
    "):\n",
    "    \"\"\"\n",
    "    –í—ã–≤–æ–¥–∏—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –º–∞—Å–∫—É.\n",
    "    –ö–∞—Ä—Ç–∏–Ω–∫–∏ –≤—ã–≤–æ–¥—è—Ç—Å—è –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ (2 —Å—Ç—Ä–æ–∫–∏), —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith(image_suffix)]\n",
    "    if not image_files:\n",
    "        print(\"–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.\")\n",
    "        return\n",
    "\n",
    "    img_name = random.choice(image_files)\n",
    "    base_name = os.path.splitext(img_name)[0]\n",
    "    mask_name = base_name + mask_suffix\n",
    "\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    mask_path = os.path.join(mask_dir, mask_name)\n",
    "\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"–ú–∞—Å–∫–∞ –¥–ª—è {img_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {mask_path}\")\n",
    "        return\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏\n",
    "    plt.figure(figsize=(6, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(f\"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img_name}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title(f\"–ú–∞—Å–∫–∞: {mask_name}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –æ—Ç–¥–µ–ª—å–Ω–æ\n",
    "    img_save_path = os.path.join(save_dir, f\"{base_name}_image.png\")\n",
    "    mask_save_path = os.path.join(save_dir, f\"{base_name}_mask.png\")\n",
    "    cv2.imwrite(img_save_path, img)\n",
    "    cv2.imwrite(mask_save_path, mask)\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img_save_path}\")\n",
    "    print(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –º–∞—Å–∫–∞: {mask_save_path}\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞:\n",
    "show_and_save_random_image_with_mask(\n",
    "    image_dir=\"./aitex_data/extracted/Defect_images\",\n",
    "    mask_dir=\"./aitex_data/extracted/Mask_images\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "SRC_MSK_DIR = Path(\"./aitex_data/extracted/Mask_images\")\n",
    "\n",
    "min_pixels = None\n",
    "max_pixels = 0\n",
    "pixels_list = []\n",
    "\n",
    "for mask_path in SRC_MSK_DIR.glob(\"*.png\"):\n",
    "    msk = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if msk is None:\n",
    "        continue\n",
    "    num = int((msk > 0).sum())\n",
    "    if num > 0:\n",
    "        pixels_list.append(num)\n",
    "        if min_pixels is None or num < min_pixels:\n",
    "            min_pixels = num\n",
    "        if num > max_pixels:\n",
    "            max_pixels = num\n",
    "\n",
    "print(f\"–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏–∫—Å–µ–ª–µ–π –¥–µ—Ñ–µ–∫—Ç–∞ –≤ –æ–¥–Ω–æ–π –º–∞—Å–∫–µ: {min_pixels}\")\n",
    "print(f\"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ: {max_pixels}\")\n",
    "print(f\"–ú–µ–¥–∏–∞–Ω–Ω–æ–µ: {np.median(pixels_list)}\")\n",
    "print(f\"–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –ø–æ –≤—Å–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º:\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(pixels_list, bins=30)\n",
    "plt.xlabel(\"–î–µ—Ñ–µ–∫—Ç–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π –Ω–∞ –º–∞—Å–∫–µ\")\n",
    "plt.ylabel(\"–ß–∞—Å—Ç–æ—Ç–∞\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSsXI-e0SWx2"
   },
   "source": [
    "## slice_to_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JeXy3qNSW8E",
    "outputId": "074b13a5-edcd-4632-ea7c-830dc8ba1e02"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- –ú–µ—Ç–∫–∏ –¥–µ—Ñ–µ–∫—Ç–æ–≤ ---\n",
    "DEFECT_LABELS = {\n",
    "    '000': 'No defect',\n",
    "    '002': 'Broken end',\n",
    "    '006': 'Broken yarn',\n",
    "    '010': 'Broken pick',\n",
    "    '016': 'Weft curling',\n",
    "    '019': 'Fuzzyball',\n",
    "    '022': 'Cut selvage',\n",
    "    '023': 'Crease',\n",
    "    '025': 'Warp ball',\n",
    "    '027': 'Knots',\n",
    "    '029': 'Contamination',\n",
    "    '030': 'Nep',\n",
    "    '036': 'Weft crack'\n",
    "}\n",
    "\n",
    "# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Ä–µ–∑–∫–∏ ---\n",
    "SRC_IMG_DIR = Path(\"./aitex_data/extracted/Defect_images\")\n",
    "SRC_MSK_DIR = Path(\"./aitex_data/extracted/Mask_images\")\n",
    "DST_IMG_DIR = Path(\"./aitex_patches/images\")\n",
    "DST_MSK_DIR = Path(\"./aitex_patches/masks\")\n",
    "\n",
    "PATCH_W = PATCH_H = 224\n",
    "STRIDE_W = STRIDE_H = (256 - 224)\n",
    "# MIN_DEFECT_FRAC = 0.005       # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –¥–µ—Ñ–µ–∫—Ç–∞\n",
    "MIN_DEFECT_PIXELS = 9 \n",
    "KEEP_NEG = 0.05\n",
    "\n",
    "DST_IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DST_MSK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "PATCH_AREA = PATCH_W * PATCH_H\n",
    "\n",
    "def has_large_defect(mask, min_size=20):\n",
    "    num_labels, _, stats, _ = cv2.connectedComponentsWithStats((mask > 0).astype(np.uint8))\n",
    "    for i in range(1, num_labels):  # 0 ‚Äî —Ñ–æ–Ω\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for img_path in tqdm(sorted(SRC_IMG_DIR.glob(\"*.png\")), desc=\"Cropping AITEX (grid)\"):\n",
    "    mask_path = SRC_MSK_DIR / img_path.name.replace(\".png\", \"_mask.png\")\n",
    "    img = cv2.imread(str(img_path))\n",
    "    msk = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None or msk is None:\n",
    "        print(f\"‚ùå  –ü—Ä–æ–ø—É—Å–∫ {img_path.name} (—Ñ–∞–π–ª–∞ –Ω–µ—Ç)\")\n",
    "        continue\n",
    "\n",
    "    msk_bin = (msk > 0).astype(np.uint8)\n",
    "    orig_defect_code_str = img_path.stem.split('_')[1]\n",
    "    orig_defect_code = int(orig_defect_code_str)\n",
    "    orig_defect_label = DEFECT_LABELS.get(orig_defect_code_str, \"Unknown\")\n",
    "\n",
    "    # –î–í–ê –¶–ò–ö–õ–ê: –ø–æ y –∏ –ø–æ x\n",
    "    for y in range(0, img.shape[0] - PATCH_H + 1, STRIDE_H):\n",
    "        for x in range(0, img.shape[1] - PATCH_W + 1, STRIDE_W):\n",
    "            img_crop = img[y:y+PATCH_H, x:x+PATCH_W]\n",
    "            msk_crop = msk_bin[y:y+PATCH_H, x:x+PATCH_W]\n",
    "            pos_pix = int(msk_crop.sum())\n",
    "            defect_frac = pos_pix / PATCH_AREA\n",
    "\n",
    "            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä\n",
    "            # is_defective = (defect_frac >= MIN_DEFECT_FRAC) or (pos_pix >= MIN_DEFECT_PIXELS)\n",
    "\n",
    "            is_defective = pos_pix >= MIN_DEFECT_PIXELS\n",
    "\n",
    "            \n",
    "            patch_defect_code = orig_defect_code\n",
    "            patch_defect_label = orig_defect_label\n",
    "\n",
    "            # –ï—Å–ª–∏ –ø–∞—Ç—á \"—á–∏—Å—Ç—ã–π\", –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–∫—É\n",
    "            if not is_defective or not has_large_defect(msk_crop, min_size=20):\n",
    "                if np.random.rand() > KEEP_NEG:\n",
    "                    continue\n",
    "                patch_defect_code = 0\n",
    "                patch_defect_label = DEFECT_LABELS['000']\n",
    "\n",
    "            suffix = f\"x{x:04d}_y{y:04d}\"\n",
    "            fname  = f\"{img_path.stem}_{suffix}.png\"\n",
    "            cv2.imwrite(str(DST_IMG_DIR / fname), img_crop)\n",
    "            cv2.imwrite(str(DST_MSK_DIR / fname), msk_crop * 255)\n",
    "            rows.append((fname, patch_defect_code, patch_defect_label))\n",
    "\n",
    "# --- –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV —Å –º–µ—Ç–∫–∞–º–∏ ---\n",
    "label_path = Path(\"./aitex_patches/patch_labels.csv\")\n",
    "label_df = pd.DataFrame(rows, columns=[\"file\", \"defect_code\", \"defect_label\"])\n",
    "label_df.to_csv(label_path, index=False)\n",
    "print(\"üìù  Saved\", len(rows), \"patch labels ‚Üí\", label_path)\n",
    "print(\"‚úÖ  –ù–∞—Ä–µ–∑–∫–∞ –ø–∞—Ç—á–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./aitex_patches/patch_labels.csv')\n",
    "has_defect = df[df['defect_label'] != 'No defect']\n",
    "no_defect  = df[df['defect_label'] == 'No defect']\n",
    "\n",
    "print(f\"–î–µ—Ñ–µ–∫—Ç–Ω—ã—Ö –ø–∞—Ç—á–µ–π: {len(has_defect)}\")\n",
    "print(f\"–ß–∏—Å—Ç—ã—Ö –ø–∞—Ç—á–µ–π: {len(no_defect)}\")\n",
    "\n",
    "desired_ratio = 1.0  # –Ω–∞–ø—Ä–∏–º–µ—Ä, 1:1\n",
    "n_defect = len(has_defect)\n",
    "n_no_defect = min(int(n_defect * desired_ratio), len(no_defect))\n",
    "\n",
    "no_defect_sampled = no_defect.sample(n=n_no_defect, random_state=42)\n",
    "df_balanced = pd.concat([has_defect, no_defect_sampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "balanced_label_path = './aitex_patches/patch_labels_balanced.csv'\n",
    "df_balanced.to_csv(balanced_label_path, index=False)\n",
    "print(f\"Balanced CSV saved: {balanced_label_path}\")\n",
    "\n",
    "# --- –ù–æ–≤—ã–π –≤—ã–≤–æ–¥ ---\n",
    "summary = df_balanced['defect_label'].value_counts().reset_index()\n",
    "summary.columns = ['defect_label', 'num_patches']\n",
    "summary['percentage'] = (summary['num_patches'] / summary['num_patches'].sum() * 100).round(2)\n",
    "\n",
    "print(\"\\n=== Patch distribution (balanced) ===\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "PATCH_LABEL_PATH = balanced_label_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_patches_with_masks_and_labels(\n",
    "    img_dir,\n",
    "    mask_dir,\n",
    "    csv_path,\n",
    "    min_defect_pixels=MIN_DEFECT_PIXELS,\n",
    "    n_pos=6,\n",
    "    n_neg=6\n",
    "):\n",
    "    \"\"\"\n",
    "    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–∞—Ç—á–∏ —Å –¥–µ—Ñ–µ–∫—Ç–æ–º –∏ –±–µ–∑ –¥–µ—Ñ–µ–∫—Ç–∞:\n",
    "    - –û—Ä–∏–≥–∏–Ω–∞–ª (RGB)\n",
    "    - –ú–∞—Å–∫–∞ (–æ—Ç–¥–µ–ª—å–Ω–æ)\n",
    "    - –ù–∞–ª–æ–∂–µ–Ω–∏–µ –º–∞—Å–∫–∏ (Mask Overlay)\n",
    "    –í –∑–∞–≥–æ–ª–æ–≤–∫–µ ‚Äî —Å—Ç–∞—Ç—É—Å (DEFECT/CLEAN) –∏ –∫–ª–∞—Å—Å –¥–µ—Ñ–µ–∫—Ç–∞.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    pos_samples, neg_samples = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        mask_path = Path(mask_dir) / row['file']\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            continue\n",
    "        defect_pixels = (mask > 0).sum()\n",
    "        info = (row['file'], row['defect_label'])\n",
    "        if defect_pixels >= min_defect_pixels:\n",
    "            pos_samples.append(info)\n",
    "        else:\n",
    "            neg_samples.append(info)\n",
    "\n",
    "    pos_samples = random.sample(pos_samples, min(n_pos, len(pos_samples)))\n",
    "    neg_samples = random.sample(neg_samples, min(n_neg, len(neg_samples)))\n",
    "    all_samples = [(fname, \"DEFECT\", label) for fname, label in pos_samples] + \\\n",
    "                  [(fname, \"CLEAN\", label) for fname, label in neg_samples]\n",
    "\n",
    "    plt.figure(figsize=(len(all_samples) * 4, 10))\n",
    "    for i, (fname, status, defect_label) in enumerate(all_samples):\n",
    "        img = cv2.imread(str(Path(img_dir) / fname))\n",
    "        mask = cv2.imread(str(Path(mask_dir) / fname), cv2.IMREAD_GRAYSCALE)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 1. –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "        plt.subplot(3, len(all_samples), i + 1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(f\"{status}\\n{defect_label}\\n{fname}\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 2. –ú–∞—Å–∫–∞ (–æ—Ç–¥–µ–ª—å–Ω–æ)\n",
    "        plt.subplot(3, len(all_samples), len(all_samples) + i + 1)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.title(\"Mask\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 3. –ù–∞–ª–æ–∂–µ–Ω–∏–µ –º–∞—Å–∫–∏\n",
    "        plt.subplot(3, len(all_samples), 2 * len(all_samples) + i + 1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.imshow(mask, cmap='Reds', alpha=0.5)\n",
    "        plt.title(\"Overlay\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- –ó–∞–ø—É—Å–∫ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ ---\n",
    "visualize_patches_with_masks_and_labels(\n",
    "    img_dir=DST_IMG_DIR,\n",
    "    mask_dir=DST_MSK_DIR,\n",
    "    csv_path=PATCH_LABEL_PATH,\n",
    "    min_defect_pixels=MIN_DEFECT_PIXELS,  # –∫–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ!\n",
    "    n_pos=3,\n",
    "    n_neg=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º\n",
    "PATCH_LABEL_PATH = './aitex_patches/patch_labels_balanced.csv'  # –∏–ª–∏ —Ç–≤–æ–π –∏—Ç–æ–≥–æ–≤—ã–π –ø—É—Ç—å\n",
    "\n",
    "# –ß—Ç–µ–Ω–∏–µ –º–µ—Ç–æ–∫\n",
    "df = pd.read_csv(PATCH_LABEL_PATH)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5603c4bf-2c6b-41e6-a789-5b3b4afb6fb1"
   },
   "source": [
    "## augmenations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_strong_classification_augmentations(image_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    –°–∏–ª—å–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è train.\n",
    "    –£—Å—Ç—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.\n",
    "    \"\"\"\n",
    "    ops = [\n",
    "        A.Resize(int(image_size[0]*1.1), int(image_size[1]*1.1)),\n",
    "        A.RandomCrop(*image_size, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Affine(\n",
    "            scale=(0.85, 1.15),\n",
    "            translate_percent=0.15,\n",
    "            rotate=(-30, 30),\n",
    "            shear=(-12, 12),\n",
    "            p=0.7\n",
    "        ),\n",
    "        A.ElasticTransform(p=0.25),  # —É–±—Ä–∞–Ω—ã –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ alpha_affine\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.2),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
    "        A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=20, val_shift_limit=15, p=0.4),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "        A.GaussNoise(p=0.4),          # var_limit –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "        A.GaussianBlur(blur_limit=(3, 9), p=0.3),\n",
    "        A.CoarseDropout(p=0.4),        # default –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    ]\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º GridMask, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω (albumentations>=1.2.0)\n",
    "    if hasattr(A, 'GridMask'):\n",
    "        ops.append(A.GridMask(num_grid=(3, 7), rotate=15, p=0.3))\n",
    "\n",
    "    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ø–µ—Ä–µ–≤–æ–¥ –≤ —Ç–µ–Ω–∑–æ—Ä\n",
    "    ops.extend([\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    return A.Compose(ops)\n",
    "\n",
    "\n",
    "def get_val_classification_augmentations(image_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    –õ—ë–≥–∫–∏–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏/—Ç–µ—Å—Ç–∞.\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(*image_size),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9564655-5c04-45e3-af7b-c6a48c992e00"
   },
   "source": [
    "## dataset_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- —Ç–≤–æ–π –∫–∞—Å—Ç–æ–º–Ω—ã–π –∫–ª–∞—Å—Å PatchDataset —Å copy-paste ---\n",
    "import random\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –ø–∞—Ç—á–µ–π —Å class-aware Copy-Paste.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (img_tensor, class_idx)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        img_dir: str,\n",
    "        transform,\n",
    "        copy_paste_prob: float = 0.3,\n",
    "        class_copy_paste: bool = True,\n",
    "        random_state: int = 42\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.copy_paste_prob = copy_paste_prob\n",
    "        self.class_copy_paste = class_copy_paste\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "\n",
    "        # mapping label ‚Üî idx\n",
    "        labels = sorted(self.df['defect_label'].unique())\n",
    "        self.label2idx = {lbl: i for i, lbl in enumerate(labels)}\n",
    "        self.idx2label = {i: lbl for lbl, i in self.label2idx.items()}\n",
    "\n",
    "        # pool –¥–µ—Ñ–µ–∫—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –ø–æ–¥—Å—á–µ—Ç –¥–µ—Ñ–∏—Ü–∏—Ç–∞ –¥–æ –º–µ–¥–∏–∞–Ω—ã\n",
    "        codes = self.df['defect_code'].values\n",
    "        files = self.df['file'].values\n",
    "        defect_mask = codes != 0\n",
    "        defect_codes = codes[defect_mask]\n",
    "        defect_files = files[defect_mask]\n",
    "\n",
    "        cnt = pd.Series(defect_codes).value_counts().to_dict()\n",
    "        median = int(np.median(list(cnt.values()))) or 1\n",
    "        deficit = {c: max(0, median - n) for c, n in cnt.items()}\n",
    "        total_def = sum(deficit.values())\n",
    "        self.class_probs = {c: d/total_def for c, d in deficit.items()} if total_def>0 else {}\n",
    "        self.defect_pool = list(zip(defect_files, defect_codes))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        fname = row['file']\n",
    "        code = int(row['defect_code'])\n",
    "        img = cv2.cvtColor(cv2.imread(str(self.img_dir / fname)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Copy-Paste –¥–ª—è —á–∏—Å—Ç—ã—Ö –ø–∞—Ç—á–µ–π\n",
    "        if code == 0 and self.defect_pool and self.rng.rand() < self.copy_paste_prob:\n",
    "            # –≤—ã–±–æ—Ä –∫–ª–∞—Å—Å–∞-–¥–æ–Ω–æ—Ä\n",
    "            if self.class_copy_paste and self.class_probs:\n",
    "                codes, probs = zip(*self.class_probs.items())\n",
    "                sel_code = int(self.rng.choice(codes, p=probs))\n",
    "                candidates = [f for f, c in self.defect_pool if c == sel_code]\n",
    "            else:\n",
    "                candidates = [f for f, _ in self.defect_pool]\n",
    "            donor = self.rng.choice(candidates)\n",
    "            donor_img = cv2.cvtColor(cv2.imread(str(self.img_dir / donor)), cv2.COLOR_BGR2RGB)\n",
    "            # –ø—Ä–æ—Å—Ç–æ–π –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—Å—Ç–∞–≤: –ø–æ –ø–∏–∫—Å–µ–ª—å–Ω–æ–º—É –æ—Ç–ª–∏—á–∏—é\n",
    "            mask = (donor_img != img).any(axis=2).astype(np.uint8)\n",
    "            for ch in range(3):\n",
    "                img[:, :, ch] = donor_img[:, :, ch] * mask + img[:, :, ch] * (1-mask)\n",
    "            code = int([c for f, c in self.defect_pool if f == donor][0])\n",
    "\n",
    "        # –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "        img = self.transform(image=img)['image']\n",
    "        label = self.label2idx[row['defect_label']]\n",
    "        return img, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset creation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_train_to_median(train_df, label_col='defect_code', random_state=42):\n",
    "    counts = train_df[label_col].value_counts()\n",
    "    median = int(counts.median())\n",
    "    upsampled = []\n",
    "    for label, cnt in counts.items():\n",
    "        df_label = train_df[train_df[label_col] == label]\n",
    "        if cnt < median:\n",
    "            n_more = median - cnt\n",
    "            sampled = df_label.sample(n=n_more, replace=True, random_state=random_state)\n",
    "            upsampled.append(sampled)\n",
    "    if upsampled:\n",
    "        train_df = pd.concat([train_df] + upsampled).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- prepare_datasets –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–∞—Ç—á–µ–π ---\n",
    "def prepare_datasets(\n",
    "    patch_label_path: str,\n",
    "    img_dir: str,\n",
    "    test_size: float = 0.05,\n",
    "    val_size: float = 0.1,\n",
    "    batch_size: int = 16,\n",
    "    num_workers: int = 4,\n",
    "    random_state: int = 42,\n",
    "    image_size: tuple = (224, 224),\n",
    "    train_aug_fn=None,\n",
    "    val_aug_fn=None,\n",
    "    copy_paste_prob: float = 0.3\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç train_ds, val_ds, test_ds (PatchDataset) —Å copy-paste –¥–ª—è train.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(patch_label_path)\n",
    "\n",
    "    # stratified split\n",
    "    train_files, test_files = train_test_split(\n",
    "        df['file'], test_size=test_size,\n",
    "        stratify=df['defect_code'], random_state=random_state\n",
    "    )\n",
    "    train_files, val_files = train_test_split(\n",
    "        train_files, test_size=val_size,\n",
    "        stratify=df[df['file'].isin(train_files)]['defect_code'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    train_df = df[df['file'].isin(train_files)].reset_index(drop=True)\n",
    "    val_df = df[df['file'].isin(val_files)].reset_index(drop=True)\n",
    "    test_df = df[df['file'].isin(test_files)].reset_index(drop=True)\n",
    "\n",
    "    # upsamples –¥–æ –º–µ–¥–∏–∞–Ω—ã\n",
    "    # train_df = upsample_train_to_median(train_df, label_col='defect_code', random_state=random_state)\n",
    "    print(\"Train class distribution\")\n",
    "    print(train_df['defect_code'].value_counts())\n",
    "\n",
    "    # transforms\n",
    "    train_transform = train_aug_fn or get_strong_classification_augmentations(image_size)\n",
    "    val_transform = val_aug_fn or get_val_classification_augmentations(image_size)\n",
    "\n",
    "    # datasets\n",
    "    train_ds = PatchDataset(\n",
    "        train_df, img_dir,\n",
    "        transform=train_transform,\n",
    "        copy_paste_prob=copy_paste_prob,\n",
    "        class_copy_paste=True,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    val_ds = PatchDataset(\n",
    "        val_df, img_dir,\n",
    "        transform=val_transform,\n",
    "        copy_paste_prob=0.0\n",
    "    )\n",
    "    test_ds = PatchDataset(\n",
    "        test_df, img_dir,\n",
    "        transform=val_transform,\n",
    "        copy_paste_prob=0.0\n",
    "    )\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader creation helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_classification_dataloaders(\n",
    "    train_ds, val_ds, test_ds,\n",
    "    batch_size: int = 16,\n",
    "    num_workers: int = 4\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    –û–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç—ã –≤ DataLoader'—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ===\n",
    "PATCH_LABEL_PATH = './aitex_patches/patch_labels_balanced.csv'\n",
    "IMG_DIR = './aitex_patches/images'\n",
    "MSK_DIR = './aitex_patches/masks'\n",
    "\n",
    "train_ds, val_ds, test_ds = prepare_datasets(\n",
    "    patch_label_path=PATCH_LABEL_PATH,\n",
    "    img_dir=IMG_DIR,\n",
    "    # msk_dir=MSK_DIR,\n",
    "    test_size=0.05,\n",
    "    val_size=0.1,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    random_state=42,\n",
    "    image_size=(PATCH_H, PATCH_W),\n",
    "    train_aug_fn=get_strong_classification_augmentations((PATCH_H, PATCH_W)),\n",
    "    val_aug_fn=get_val_classification_augmentations((PATCH_H, PATCH_W)),\n",
    "    copy_paste_prob=0.8\n",
    ")\n",
    "\n",
    "print(\"label2idx:\", train_ds.label2idx)\n",
    "print(\"idx2label:\", train_ds.idx2label)\n",
    "print(\"–í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤:\", len(train_ds.label2idx))\n",
    "\n",
    "train_loader, val_loader, test_loader = get_classification_dataloaders(\n",
    "    train_ds, val_ds, test_ds,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_weighted_loss(train_ds, smoothing=0.1, device='cuda'):\n",
    "    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç–∫–∏ –∏–∑ train_ds\n",
    "    train_labels = [label for _, label in train_ds]\n",
    "\n",
    "    # –ü–æ–¥—Å—á—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "    class_counts = Counter(train_labels)\n",
    "    num_classes = len(train_ds.label2idx)\n",
    "    total_samples = len(train_labels)\n",
    "\n",
    "    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Å–∞ (–æ–±—Ä–∞—Ç–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞)\n",
    "    class_weights = np.zeros(num_classes)\n",
    "    for cls_idx in range(num_classes):\n",
    "        cls_count = class_counts.get(cls_idx, 0)\n",
    "        class_weights[cls_idx] = total_samples / (num_classes * cls_count)\n",
    "\n",
    "    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤\n",
    "    class_weights = class_weights / class_weights.sum() * num_classes\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º –≤–∑–≤–µ—à–µ–Ω–Ω—É—é CrossEntropyLoss —Å label smoothing\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=smoothing)\n",
    "    return loss_fn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def print_class_distribution_from_dataset(dataset, label_names=None, title=\"Train set\"):\n",
    "    \"\"\"\n",
    "    –í—ã–≤–æ–¥–∏—Ç —Ç–∞–±–ª–∏—Ü—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—Ç—á–µ–π –ø–æ –∫–ª–∞—Å—Å–∞–º –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è).\n",
    "    - dataset: —ç–∫–∑–µ–º–ø–ª—è—Ä Dataset (–Ω–∞–ø—Ä–∏–º–µ—Ä, PatchClassificationDataset –∏–ª–∏ AITEXPatchDataset)\n",
    "    - label_names: dict –¥–ª—è –∫—Ä–∞—Å–∏–≤—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤ {idx: name} –∏–ª–∏ {code: name}\n",
    "    - title: –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –≤—ã–≤–æ–¥–∞\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        try:\n",
    "            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (img, label) –∏–ª–∏ (img, mask, label)\n",
    "            if hasattr(dataset, \"idx2label\"):\n",
    "                # –ò–Ω–¥–µ–∫—Å ‚Üí —Å—Ç—Ä–æ–∫–∞ –∫–ª–∞—Å—Å–∞\n",
    "                _, label = dataset[i][:2]\n",
    "                class_label = dataset.idx2label[label]\n",
    "            else:\n",
    "                # –ù–∞–ø—Ä–∏–º–µ—Ä, (img, mask, code, label)\n",
    "                *_, label = dataset[i]\n",
    "                class_label = label\n",
    "        except Exception:\n",
    "            # –õ—é–±–æ–π fallback\n",
    "            class_label = \"unknown\"\n",
    "        labels.append(class_label)\n",
    "\n",
    "    df = pd.DataFrame({'class_label': labels})\n",
    "    summary = df['class_label'].value_counts().reset_index()\n",
    "    summary.columns = ['class_label', 'num_patches']\n",
    "    summary['percentage'] = (summary['num_patches'] / summary['num_patches'].sum() * 100).round(2)\n",
    "    if label_names:\n",
    "        summary['class_label'] = summary['class_label'].map(label_names).fillna(summary['class_label'])\n",
    "    print(f\"\\n=== Patch distribution in {title} ===\")\n",
    "    print(summary.to_string(index=False))\n",
    "\n",
    "\n",
    "print_class_distribution_from_dataset(train_ds, label_names=DEFECT_LABELS, title=\"Train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:13:36.398507Z",
     "iopub.status.busy": "2025-05-17T08:13:36.397903Z",
     "iopub.status.idle": "2025-05-17T08:13:36.402238Z",
     "shell.execute_reply": "2025-05-17T08:13:36.401567Z",
     "shell.execute_reply.started": "2025-05-17T08:13:36.398482Z"
    }
   },
   "source": [
    "## visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def visualize_classification_dataset_grid(dataset, num_samples=6, label_names=None):\n",
    "    \"\"\"\n",
    "    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:\n",
    "    - –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ ‚Äî —Ä–∞–∑–Ω—ã–µ –ø–∞—Ç—á–∏/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (num_samples)\n",
    "    - –¢–æ–ª—å–∫–æ 1 —Ä—è–¥: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "    - –í –∑–∞–≥–æ–ª–æ–≤–∫–µ: –∫–æ–¥ –∏ (–ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏) –∫—Ä–∞—Å–∏–≤—ã–π –ª–µ–π–±–ª –∫–ª–∞—Å—Å–∞\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    plt.figure(figsize=(num_samples * 4, 4))\n",
    "\n",
    "    for col, idx in enumerate(indices):\n",
    "        sample = dataset[idx]\n",
    "        # –û–∂–∏–¥–∞–µ—Ç—Å—è (img, class_code, class_label) –∏–ª–∏ (img, class_code)\n",
    "        if len(sample) == 3:\n",
    "            image, code, label = sample\n",
    "        elif len(sample) == 2:\n",
    "            image, code = sample\n",
    "            label = str(code)\n",
    "        else:\n",
    "            image = sample[0]\n",
    "            code = None\n",
    "            label = \"unknown\"\n",
    "\n",
    "        # –ö—Ä–∞—Å–∏–≤–æ–µ –∏–º—è –∫–ª–∞—Å—Å–∞\n",
    "        if label_names is not None:\n",
    "            class_name = label_names.get(str(code), str(label))\n",
    "        else:\n",
    "            class_name = str(label)\n",
    "\n",
    "        title = f\"Code: {code}\\nLabel: {class_name}\"\n",
    "\n",
    "        # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ —Ç–µ–Ω–∑–æ—Ä\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            rgb = image[:3].permute(1, 2, 0).cpu().numpy()\n",
    "            rgb = (rgb * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)\n",
    "        else:\n",
    "            rgb = image\n",
    "\n",
    "        plt.subplot(1, num_samples, col + 1)\n",
    "        plt.imshow(rgb)\n",
    "        plt.title(title, fontsize=11)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_classification_dataset_grid(train_ds, num_samples=8, label_names=DEFECT_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d1ff18c-c131-45de-9398-aede203360ae"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3255ae5-59eb-4535-8ef5-ac60786a3d78"
   },
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf07f1c4-b824-4326-83d7-182705364d64"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data.mixup import Mixup\n",
    "\n",
    "# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MixUp + CutMix ---\n",
    "mixup_fn = Mixup(\n",
    "    mixup_alpha=0.4,        # \"—Å–º–µ—à–∏–≤–∞–Ω–∏–µ\" ‚Äî —Ç–∏–ø–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "    cutmix_alpha=1.0,       # CutMix —Ç–æ–∂–µ –≤–∫–ª—é—á—ë–Ω (–æ–±—ã—á–Ω–æ 0.5-1.0, –º–æ–∂–Ω–æ –ø–æ–∏–≥—Ä–∞—Ç—å—Å—è)\n",
    "    label_smoothing=0.1,    # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –µ—Å–ª–∏ —É —Ç–µ–±—è –∏ —Ç–∞–∫ —Å—Ç–æ–∏—Ç ‚Äî –º–æ–∂–Ω–æ —á—É—Ç—å —Å–Ω–∏–∑–∏—Ç—å\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "753ae338-0818-4155-a3a1-0f41f531c633"
   },
   "source": [
    "#### train_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbe9d1a7-7977-4887-9cdb-49631ed48270"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from timm.utils import ModelEmaV2\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model, train_loader, optimizer, loss_fn, scaler,\n",
    "    device, epoch, model_name, num_classes,\n",
    "    mixup_fn=None, ema=None\n",
    "):\n",
    "    \"\"\"\n",
    "    –û–¥–Ω–∞ —ç–ø–æ—Ö–∞ –æ–±—É—á–µ–Ω–∏—è —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º MixUp/CutMix –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º EMA.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è train.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_probs, all_targets = [], [], []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_loader, desc=f\"Train {epoch}\")):\n",
    "        images, labels = batch[:2]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # MIXUP / CUTMIX\n",
    "        if mixup_fn:\n",
    "            images, labels = mixup_fn(images, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(enabled=(device.type=='cuda')):\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # backward + step\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # EMA update\n",
    "        if ema is not None:\n",
    "            ema.update(model)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # accumulate predictions\n",
    "        probs = torch.softmax(outputs.detach(), dim=1).cpu().numpy()\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        all_preds.append(preds)\n",
    "        all_probs.append(probs)\n",
    "        if labels.dtype == torch.float32:\n",
    "            all_targets.append(labels.argmax(dim=1).cpu().numpy())\n",
    "        else:\n",
    "            all_targets.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_targets)\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_prob = np.concatenate(all_probs)\n",
    "\n",
    "    metrics = compute_classification_metrics(y_true, y_pred, y_prob, num_classes)\n",
    "    metrics['loss'] = running_loss / len(train_loader)\n",
    "    print(f\"[{model_name}] Train epoch {epoch}: {metrics}\")\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d138719-faf4-4542-9e15-d2a65f9ee065"
   },
   "source": [
    "#### validate_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4ea0489-92c9-468b-804a-fb298be2ac67"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate_epoch(\n",
    "    model, val_loader, device, epoch, model_name, num_classes\n",
    "):\n",
    "    \"\"\"\n",
    "    –û–¥–Ω–∞ —ç–ø–æ—Ö–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–æ–±—ã—á–Ω–æ EMA).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_probs, all_targets = [], [], []\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(tqdm(val_loader, desc=f\"Val  {epoch}\")):\n",
    "            images, labels = batch[:2]\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs.cpu(), dim=1).numpy()\n",
    "            preds = np.argmax(probs, axis=1)\n",
    "            all_preds.append(preds)\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_targets)\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_prob = np.concatenate(all_probs)\n",
    "\n",
    "    metrics = compute_classification_metrics(y_true, y_pred, y_prob, num_classes)\n",
    "    metrics['loss'] = running_loss / len(val_loader)\n",
    "    print(f\"[{model_name}] Val epoch {epoch}: {metrics}\")\n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce566e89-fcb2-4fc9-b633-7f40426ae8a0"
   },
   "source": [
    "### train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf9f600f-462d-4d7f-9edb-9dc8f1f6bb20"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(\n",
    "    model, optimizer, scheduler,\n",
    "    train_loader, val_loader,\n",
    "    loss_fn, device, scaler,\n",
    "    num_classes,\n",
    "    num_epochs=50, early_stop_patience=5,\n",
    "    model_name='model', mixup_fn=None,\n",
    "    ema_decay: float = 0.9999\n",
    "):\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–∞—è –ø–µ—Ç–ª—è –æ–±—É—á–µ–Ω–∏—è —Å EMA, scheduler –∏ early-stopping –ø–æ macro-F1.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ train –∏ val.\n",
    "    \"\"\"\n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EMA\n",
    "    ema = ModelEmaV2(model, decay=ema_decay, device=device)\n",
    "    best_f1 = 0.0\n",
    "    counter = 0\n",
    "    train_history, val_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train\n",
    "        train_metrics = train_epoch(\n",
    "            model, train_loader, optimizer, loss_fn, scaler,\n",
    "            device, epoch, model_name, num_classes,\n",
    "            mixup_fn=mixup_fn, ema=ema\n",
    "        )\n",
    "        # val –Ω–∞ EMA-–º–æ–¥–µ–ª–∏\n",
    "        ema_model = ema.module\n",
    "        val_metrics = validate_epoch(\n",
    "            ema_model, val_loader, device, epoch, model_name, num_classes\n",
    "        )\n",
    "\n",
    "        scheduler.step(val_metrics['f1_macro'])\n",
    "        train_history.append(train_metrics)\n",
    "        val_history.append(val_metrics)\n",
    "\n",
    "        # early stopping + —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö\n",
    "        if val_metrics['f1_macro'] > best_f1:\n",
    "            best_f1 = val_metrics['f1_macro']\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_{model_name}.pth\")\n",
    "            ema_state = ema.state_dict()\n",
    "            torch.save(ema_state, f\"ema_{model_name}.pth\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= early_stop_patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        print(f\"Epoch {epoch}: Train F1(macro)={train_metrics['f1_macro']:.4f}  Val F1(macro)={val_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "    print(f\"Best Val F1(macro): {best_f1:.4f}\")\n",
    "    return train_history, val_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(train_history, val_history, model_name, save_path=None):\n",
    "    keys = ['loss', 'accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'top1', 'top3']\n",
    "    n_keys = len(keys)\n",
    "    n_cols = 3  # –ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å 4 ‚Äî –±—É–¥–µ—Ç –±–æ–ª–µ–µ —Ä–∞—Å—Ç—è–Ω—É—Ç–æ\n",
    "    n_rows = math.ceil(n_keys / n_cols)\n",
    "    plt.figure(figsize=(n_cols * 6, n_rows * 4))\n",
    "    for idx, key in enumerate(keys, 1):\n",
    "        plt.subplot(n_rows, n_cols, idx)\n",
    "        train_vals = [m.get(key, 0) for m in train_history]\n",
    "        val_vals = [m.get(key, 0) for m in val_history]\n",
    "        plt.plot(train_vals, label=f\"Train {key}\")\n",
    "        plt.plot(val_vals, label=f\"Val {key}\")\n",
    "        plt.title(f\"{model_name}: {key}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ae365e2-c328-4044-8043-7e795ff63d0d"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_single_model(\n",
    "    model_name, model_fn,\n",
    "    train_loader, val_loader,\n",
    "    config, num_classes,\n",
    "    mixup_fn=None\n",
    "):\n",
    "    \"\"\"\n",
    "    –¢—Ä–µ–Ω–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å —Å EMA, OneCycleLR –∏ weighted loss + smoothing.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model_fn().to(device)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config['learning_rate'],\n",
    "        total_steps=len(train_loader)*config['num_epochs'],\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0\n",
    "    )\n",
    "    # –í–∑–≤–µ—à–µ–Ω–Ω—ã–π loss + smoothing\n",
    "    loss_fn = get_weighted_loss(train_ds, smoothing=config.get('smoothing',0.1), device=device)\n",
    "    scaler = GradScaler(enabled=(device.type=='cuda'))\n",
    "\n",
    "    return train_loop(\n",
    "        model, optimizer, scheduler,\n",
    "        train_loader, val_loader,\n",
    "        loss_fn, device, scaler,\n",
    "        num_classes,\n",
    "        num_epochs=config['num_epochs'],\n",
    "        early_stop_patience=config['early_stop_patience'],\n",
    "        model_name=model_name,\n",
    "        mixup_fn=mixup_fn,\n",
    "        ema_decay=config.get('ema_decay',0.9999)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0014b2c-1b67-4a7f-aa97-281f74a127cf"
   },
   "source": [
    "## train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:31:34.969449Z",
     "iopub.status.busy": "2025-05-17T08:31:34.968855Z",
     "iopub.status.idle": "2025-05-17T08:31:34.972959Z",
     "shell.execute_reply": "2025-05-17T08:31:34.972253Z",
     "shell.execute_reply.started": "2025-05-17T08:31:34.969421Z"
    }
   },
   "source": [
    "## run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def train_all_models(models_dict, train_loader, val_loader, config, num_classes, mixup_fn=None):\n",
    "    for name, model_fn in models_dict.items():\n",
    "        print(f\"==== Training model: {name} ====\")\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "        train_hist, val_hist = train_single_model(\n",
    "            name, model_fn, train_loader, val_loader, config, num_classes, mixup_fn=mixup_fn\n",
    "        )\n",
    "        plot_metrics(train_hist, val_hist, model_name=name, save_path=f\"metrics_{name}.png\")\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "train_all_models(MODELS, train_loader, val_loader, CONFIG, NUM_CLASSES, mixup_fn=mixup_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e842448e-1511-420a-80ae-604b9906ee7e"
   },
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "613d4e65-8746-43cf-84b5-c2b1500b33f1"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69248cf9-4a14-42ac-a7a3-1078ee5412e4"
   },
   "source": [
    "### tta_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99356348-3504-45cf-a379-fb48203fed90"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def tta_predict_classification(model, images):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–º–µ–Ω—è–µ—Ç TTA –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: –æ—Ä–∏–≥–∏–Ω–∞–ª + –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É—Å—Ä–µ–¥–Ω—ë–Ω–Ω—ã–µ logits.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        orig = model(images)\n",
    "        flip_imgs = torch.flip(images, dims=[3])\n",
    "        flip_preds = model(flip_imgs)\n",
    "        # –ù–ï –Ω–∞–¥–æ –æ–±—Ä–∞—Ç–Ω–æ –æ—Ç—Ä–∞–∂–∞—Ç—å flip_preds –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏!\n",
    "        # –ü—Ä–æ—Å—Ç–æ —É—Å—Ä–µ–¥–Ω—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏/–ª–æ–≥–∏—Ç—ã\n",
    "        return (orig + flip_preds) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96c786e1-1cfa-4043-88f9-f4a5693ade51"
   },
   "source": [
    "### visualize_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fb48f84b-6b6d-42b3-ade3-422749fe74e7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def visualize_classification_predictions_tta(\n",
    "    model,\n",
    "    dataloader,\n",
    "    device,\n",
    "    label_names=None,\n",
    "    num_samples=10,\n",
    "    imagenet_norm=True,\n",
    "    model_title=None\n",
    "):\n",
    "    \"\"\"\n",
    "    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞:\n",
    "    1. –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "    2. –ò—Å—Ç–∏–Ω–Ω–∞—è –º–µ—Ç–∫–∞ (GT)\n",
    "    3. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–µ—Ç–∫–∞ (TTA)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    images_list = []\n",
    "    gt_labels_list = []\n",
    "    pred_labels_list = []\n",
    "    titles = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è c TTA\n",
    "            logits = tta_predict_classification(model, images)\n",
    "            probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "            preds = np.argmax(probs, axis=1)\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            for i in range(batch_size):\n",
    "                if shown >= num_samples:\n",
    "                    break\n",
    "\n",
    "                img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "                if imagenet_norm:\n",
    "                    img = (img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)\n",
    "                gt_idx = labels[i]\n",
    "                pred_idx = preds[i]\n",
    "                gt_name = label_names.get(gt_idx, str(gt_idx)) if label_names else str(gt_idx)\n",
    "                pred_name = label_names.get(pred_idx, str(pred_idx)) if label_names else str(pred_idx)\n",
    "\n",
    "                title = f\"GT: {gt_name}\\nPred: {pred_name}\"\n",
    "                images_list.append(img)\n",
    "                titles.append(title)\n",
    "\n",
    "                shown += 1\n",
    "            if shown >= num_samples:\n",
    "                break\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    plt.figure(figsize=(num_samples * 3, 4))\n",
    "    if model_title is not None:\n",
    "        plt.suptitle(model_title, fontsize=16, y=1.08)\n",
    "    for col in range(shown):\n",
    "        plt.subplot(1, num_samples, col + 1)\n",
    "        plt.imshow(images_list[col])\n",
    "        plt.title(titles[col], fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "idx2label = train_ds.idx2label  # –ò–ª–∏ —Å–≤–æ–π —Å–ª–æ–≤–∞—Ä—å {int: str}\n",
    "\n",
    "for model_name in MODELS:\n",
    "    checkpoint_path = f'best_{model_name}.pth'\n",
    "    print(f\"\\n--- Model: {model_name} ---\")\n",
    "    try:\n",
    "        test_model = MODELS[model_name]().to(device)\n",
    "        test_model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        test_model.eval()\n",
    "        \n",
    "        visualize_classification_predictions_tta(\n",
    "            test_model,\n",
    "            dataloader=test_loader,\n",
    "            device=device,\n",
    "            label_names=idx2label,\n",
    "            num_samples=5,\n",
    "            model_title=f\"Model: {model_name}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not evaluate {model_name}: {e}\")\n",
    "    finally:\n",
    "        del test_model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb943ece-2f41-4c50-834d-9a1edf782ca1"
   },
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def classification_sanity_check(\n",
    "    train_ds, MODELS, device, target_label=None, num_epochs=20, N=8, idx2label=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Sanity check: –±—ã—Å—Ç—Ä–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –ø–∞—Ç—á–µ (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è).\n",
    "    –ï—Å–ª–∏ target_label –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –±–µ—Ä—ë—Ç –ø–µ—Ä–≤—ã–π –ø–æ–ø–∞–≤—à–∏–π—Å—è –ø–∞—Ç—á.\n",
    "    –ï—Å–ª–∏ –∑–∞–¥–∞–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, \"No defect\" –∏–ª–∏ \"Broken end\"), –±–µ—Ä—ë—Ç –ø–µ—Ä–≤—ã–π –ø–∞—Ç—á —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞.\n",
    "    \"\"\"\n",
    "    # 1. –ù–∞–π—Ç–∏ –ø–∞—Ç—á —Å –Ω—É–∂–Ω—ã–º –∫–ª–∞—Å—Å–æ–º\n",
    "    idx = None\n",
    "    for i in range(len(train_ds)):\n",
    "        img, label = train_ds[i]\n",
    "        if (target_label is None) or (idx2label and idx2label[label] == target_label):\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        raise RuntimeError(\"–ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–∞—Ç—á –¥–ª—è sanity check!\")\n",
    "    img, label = train_ds[idx]\n",
    "\n",
    "    print(f\"Sanity check: –ø–∞—Ç—á –∫–ª–∞—Å—Å–∞ '{idx2label[label] if idx2label else label}' (–∏–Ω–¥–µ–∫—Å {label})\")\n",
    "\n",
    "    # 2. –î–µ–ª–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ N –∫–æ–ø–∏–π —ç—Ç–æ–≥–æ –ø–∞—Ç—á–∞\n",
    "    single_ds = [(img, label)] * N\n",
    "    single_loader = DataLoader(single_ds, batch_size=N, shuffle=True)\n",
    "\n",
    "    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏\n",
    "    for model_name, model_fn in MODELS.items():\n",
    "        print(f\"\\n==== Sanity check: {model_name} ====\")\n",
    "        model = model_fn().to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        losses, accs = [], []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for img_batch, label_batch in single_loader:\n",
    "                img_batch = img_batch.to(device)\n",
    "                label_batch = label_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(img_batch)\n",
    "                loss = loss_fn(output, label_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞: —Ç–æ—á–Ω–æ—Å—Ç—å –∏ –¥–∏–Ω–∞–º–∏–∫–∞\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(img_batch)\n",
    "                probs = torch.softmax(output, dim=1)\n",
    "                pred_class = probs.argmax(dim=1).cpu().numpy()\n",
    "                gt_class = label_batch.cpu().numpy()\n",
    "                acc = (pred_class == gt_class).mean()\n",
    "            losses.append(loss.item())\n",
    "            accs.append(acc)\n",
    "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}, Acc = {acc:.3f}, GT: {idx2label[gt_class[0]] if idx2label else gt_class[0]}, Pred: {idx2label[pred_class[0]] if idx2label else pred_class[0]}\")\n",
    "\n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è loss/accuracy\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "        axs[0].plot(losses, label=\"Loss\")\n",
    "        axs[0].set_title(f\"{model_name} Loss\")\n",
    "        axs[1].plot(accs, label=\"Acc\")\n",
    "        axs[1].set_title(f\"{model_name} Accuracy\")\n",
    "        for ax in axs: ax.grid(); ax.set_xlabel('Epoch')\n",
    "        plt.suptitle(f\"Sanity Check: {model_name} ‚Äî –∫–ª–∞—Å—Å '{idx2label[label] if idx2label else label}'\")\n",
    "        plt.show()\n",
    "\n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–∞–º–æ–≥–æ –ø–∞—Ç—á–∞\n",
    "        img_np = img[:3].permute(1,2,0).cpu().numpy() if isinstance(img, torch.Tensor) else img\n",
    "        img_np = (img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0,1)\n",
    "        plt.figure(figsize=(3,3))\n",
    "        plt.imshow(img_np)\n",
    "        plt.title(f\"Class: {idx2label[label] if idx2label else label}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# === –ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞ ===\n",
    "# –î–ª—è –ª—é–±–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–ø–µ—Ä–≤—ã–π –ø–æ–ø–∞–≤—à–∏–π—Å—è):\n",
    "classification_sanity_check(\n",
    "    train_ds, MODELS, device,\n",
    "    target_label=None,     # –∏–ª–∏ –Ω–∞–ø—Ä–∏–º–µ—Ä \"No defect\"\n",
    "    num_epochs=20, N=8,\n",
    "    idx2label=train_ds.idx2label\n",
    ")\n",
    "\n",
    "# –î–ª—è \"—á–∏—Å—Ç–æ–≥–æ\" –ø–∞—Ç—á–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ):\n",
    "classification_sanity_check(\n",
    "    train_ds, MODELS, device,\n",
    "    target_label=\"No defect\",\n",
    "    num_epochs=20, N=8,\n",
    "    idx2label=train_ds.idx2label\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def classification_sanity_check(train_ds, MODELS, device, target_label=None, num_epochs=20, N=8):\n",
    "    \"\"\"\n",
    "    Sanity check: –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –∑–∞—Ñ–∏—Ç–∏—Ç—å—Å—è –Ω–∞ –æ–¥–Ω–æ–º –∏ —Ç–æ–º –∂–µ –ø–∞—Ç—á–µ (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è).\n",
    "    target_label: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω, –∏—â–µ—Ç –ø–µ—Ä–≤—ã–π –ø–∞—Ç—á —Å —ç—Ç–∏–º label.\n",
    "                  –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –¥–µ—Ñ–µ–∫—Ç–Ω–æ–≥–æ: target_label != 'No defect'\n",
    "                  –î–ª—è —á–∏—Å—Ç–æ–≥–æ: target_label == 'No defect'\n",
    "    \"\"\"\n",
    "    # 1. –ù–∞–π—Ç–∏ –ø–∞—Ç—á –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—é\n",
    "    idx = None\n",
    "    for i in range(len(train_ds)):\n",
    "        img, label = train_ds[i]\n",
    "        if target_label is None or train_ds.idx2label[label] == target_label:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        raise RuntimeError(\"–ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–∞—Ç—á –¥–ª—è sanity check!\")\n",
    "    img, label = train_ds[idx]\n",
    "\n",
    "    # 2. –î–µ–ª–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ N –∫–æ–ø–∏–π –æ–¥–Ω–æ–≥–æ –ø–∞—Ç—á–∞\n",
    "    single_ds = [(img, label)] * N\n",
    "    single_loader = DataLoader(single_ds, batch_size=N, shuffle=True)\n",
    "\n",
    "    for model_name, model_fn in MODELS.items():\n",
    "        print(f\"\\n==== Sanity check: {model_name} ====\")\n",
    "        model = model_fn().to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for img_batch, label_batch in single_loader:\n",
    "                img_batch = img_batch.to(device)\n",
    "                label_batch = label_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(img_batch)\n",
    "                loss = loss_fn(output, label_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(img_batch)\n",
    "                probs = torch.softmax(output, dim=1)\n",
    "                pred_class = probs.argmax(dim=1).cpu().numpy()\n",
    "                gt_class = label_batch.cpu().numpy()\n",
    "                acc = (pred_class == gt_class).mean()\n",
    "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}, Acc = {acc:.3f}, GT: {train_ds.idx2label[gt_class[0]]}, Pred: {train_ds.idx2label[pred_class[0]]}\")\n",
    "\n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ç—á–∞\n",
    "        img_np = img[:3].permute(1,2,0).cpu().numpy() if isinstance(img, torch.Tensor) else img\n",
    "        img_np = (img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0,1)\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(img_np)\n",
    "        plt.title(f\"Sanity Check: {model_name}\\nClass: {train_ds.idx2label[label]}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41909dd6-9ae4-4a24-80b3-bac29015e091"
   },
   "outputs": [],
   "source": [
    "classification_sanity_check(train_ds, MODELS, device, target_label='Broken end', num_epochs=20, N=8)\n",
    "# (–∏–ª–∏ target_label != 'No defect', –µ—Å–ª–∏ —Ö–æ—á–µ—Ç—Å—è –ø–æ–¥–æ–±—Ä–∞—Ç—å –∏–º–µ–Ω–Ω–æ –¥–µ—Ñ–µ–∫—Ç)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_sanity_check(train_ds, MODELS, device, target_label='No defect', num_epochs=20, N=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def infer_full_image_classification_with_models(\n",
    "    image,\n",
    "    models_dict,\n",
    "    preprocess,\n",
    "    patch_h=224,\n",
    "    patch_w=224,\n",
    "    stride_h=64,\n",
    "    stride_w=64,\n",
    "    device='cuda',\n",
    "    model_names=None,\n",
    "    config=None\n",
    "):\n",
    "    \"\"\"\n",
    "    –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—á–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict: {model_name: 2D array of class indices}, –∞ —Ç–∞–∫–∂–µ coords –≤—Å–µ—Ö –ø–∞—Ç—á–µ–π.\n",
    "    \"\"\"\n",
    "    H, W, C = image.shape\n",
    "    if model_names is None:\n",
    "        model_names = list(models_dict.keys())\n",
    "    batch_size = config[\"batch_size\"] if config and \"batch_size\" in config else 8\n",
    "\n",
    "    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—á–∞ —Ö—Ä–∞–Ω–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ patch\n",
    "    patch_coords = []\n",
    "    patches = []\n",
    "    for y in range(0, H - patch_h + 1, stride_h):\n",
    "        for x in range(0, W - patch_w + 1, stride_w):\n",
    "            patch = image[y:y+patch_h, x:x+patch_w]\n",
    "            patches.append(patch)\n",
    "            patch_coords.append((y, x))\n",
    "    patch_tensors = [preprocess(p) for p in patches]\n",
    "    patch_batch = torch.stack(patch_tensors)  # [N, C, H, W]\n",
    "\n",
    "    # –°–ª–æ–≤–∞—Ä—å: –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ ‚Äî —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—á–∞\n",
    "    results_dict = {}\n",
    "    for model_name in model_names:\n",
    "        torch.cuda.empty_cache()\n",
    "        model = models_dict[model_name]().to(device)\n",
    "        model.eval()\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(f'best_{model_name}.pth', map_location=device))\n",
    "        except Exception as e:\n",
    "            print(f\"[{model_name}] checkpoint not loaded: {e}\")\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(patch_batch), batch_size):\n",
    "                batch = patch_batch[i:i+batch_size].to(device)\n",
    "                logits = model(batch)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                pred_class = probs.argmax(dim=1).cpu().numpy()\n",
    "                preds.append(pred_class)\n",
    "                del batch, logits, probs\n",
    "                torch.cuda.empty_cache()\n",
    "        preds = np.concatenate(preds, axis=0)  # [num_patches]\n",
    "\n",
    "        # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—É—é \"–∫–∞—Ä—Ç—É\" –∫–ª–∞—Å—Å–æ–≤ (–∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ–º –ø–∞—Ç—á–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ 2D-–º–∞—Ç—Ä–∏—Ü—É)\n",
    "        map_H = (H - patch_h) // stride_h + 1\n",
    "        map_W = (W - patch_w) // stride_w + 1\n",
    "        class_map = preds.reshape(map_H, map_W)\n",
    "        results_dict[model_name] = class_map\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    del patch_batch, patch_tensors, patches\n",
    "    torch.cuda.empty_cache()\n",
    "    return results_dict, patch_coords, (map_H, map_W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def show_classification_map(\n",
    "    image, class_map, patch_h, patch_w, stride_h, stride_w, idx2label=None, model_name=\"Model\"\n",
    "):\n",
    "    \"\"\"\n",
    "    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∫–∞—Ä—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ (–ø—Å–µ–≤–¥–æ—Ü–≤–µ—Ç).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{model_name}: Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # \"—Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º\" –∫–∞—Ä—Ç—É –≤ –∏—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏\n",
    "    H, W = image.shape[:2]\n",
    "    map_H, map_W = class_map.shape\n",
    "    vis_map = np.zeros((H, W), dtype=np.int32)\n",
    "    for i in range(map_H):\n",
    "        for j in range(map_W):\n",
    "            y = i * stride_h\n",
    "            x = j * stride_w\n",
    "            vis_map[y:y+patch_h, x:x+patch_w] = class_map[i, j]\n",
    "    cmap = plt.get_cmap('tab20' if class_map.max() < 20 else 'nipy_spectral')\n",
    "    im = plt.imshow(vis_map, cmap=cmap, vmin=0, vmax=class_map.max())\n",
    "    plt.title(f\"{model_name}: Predicted Classes Map\")\n",
    "    plt.axis('off')\n",
    "    cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    if idx2label:\n",
    "        labels = [idx2label[i] for i in range(class_map.max() + 1)]\n",
    "        cbar.set_ticks(range(len(labels)))\n",
    "        cbar.set_ticklabels(labels)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def save_classification_map_image(\n",
    "    image, class_map, patch_h, patch_w, stride_h, stride_w, idx2label=None,\n",
    "    model_name=\"Model\", save_dir=\"./inference_results\", img_id=0\n",
    "):\n",
    "    \"\"\"\n",
    "    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –∫–∞—Ä—Ç—ã –∫–ª–∞—Å—Å–æ–≤, –Ω–∞–ª–æ–∂–µ–Ω–Ω–æ–π –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    H, W = image.shape[:2]\n",
    "    map_H, map_W = class_map.shape\n",
    "    vis_map = np.zeros((H, W), dtype=np.int32)\n",
    "    for i in range(map_H):\n",
    "        for j in range(map_W):\n",
    "            y = i * stride_h\n",
    "            x = j * stride_w\n",
    "            vis_map[y:y+patch_h, x:x+patch_w] = class_map[i, j]\n",
    "    cmap = plt.get_cmap('tab20' if class_map.max() < 20 else 'nipy_spectral')\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ RGB (—Ü–≤–µ—Ç–Ω—É—é –∫–∞—Ä—Ç—É –∫–ª–∞—Å—Å–æ–≤)\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{model_name}: Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    im = plt.imshow(vis_map, cmap=cmap, vmin=0, vmax=class_map.max())\n",
    "    plt.title(f\"{model_name}: Predicted Classes Map\")\n",
    "    plt.axis('off')\n",
    "    cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    if idx2label:\n",
    "        labels = [idx2label[i] for i in range(class_map.max() + 1)]\n",
    "        cbar.set_ticks(range(len(labels)))\n",
    "        cbar.set_ticklabels(labels)\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(save_dir, f\"{model_name}_classmap_{img_id}.png\")\n",
    "    plt.savefig(fname, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "    print(f\"Saved: {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø–∞—Ç—á–µ–π ---\n",
    "preprocess_albu = A.Compose([\n",
    "    A.Resize(PATCH_H, PATCH_W),  # 224, 224\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "def preprocess_patch(patch):\n",
    "    return preprocess_albu(image=patch)['image']\n",
    "\n",
    "# --- –í—ã–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---\n",
    "IMG_DIR = Path('./aitex_data/extracted/Defect_images')\n",
    "img_files = sorted(list(IMG_DIR.glob('*.png')))\n",
    "img_path = img_files[0]\n",
    "\n",
    "img = cv2.imread(str(img_path))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# --- –ò–Ω—Ñ–µ—Ä–µ–Ω—Å ---\n",
    "result_classmaps, patch_coords, (map_H, map_W) = infer_full_image_classification_with_models(\n",
    "    img,\n",
    "    models_dict=MODELS,\n",
    "    preprocess=preprocess_patch,\n",
    "    patch_h=PATCH_H,\n",
    "    patch_w=PATCH_W,\n",
    "    stride_h=STRIDE_H,\n",
    "    stride_w=STRIDE_W,\n",
    "    device=device,\n",
    "    config=CONFIG\n",
    ")\n",
    "\n",
    "# --- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ---\n",
    "for model_name, class_map in result_classmaps.items():\n",
    "    show_classification_map(\n",
    "        img, class_map,\n",
    "        patch_h=PATCH_H, patch_w=PATCH_W,\n",
    "        stride_h=STRIDE_H, stride_w=STRIDE_W,\n",
    "        idx2label=train_ds.idx2label,  # –∏–ª–∏ —Å–≤–æ–π —Å–ª–æ–≤–∞—Ä—å {int: str}\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "save_dir = \"./inference_results\"\n",
    "for idx, (model_name, class_map) in enumerate(result_classmaps.items()):\n",
    "    save_classification_map_image(\n",
    "        img, class_map,\n",
    "        patch_h=PATCH_H, patch_w=PATCH_W,\n",
    "        stride_h=STRIDE_H, stride_w=STRIDE_W,\n",
    "        idx2label=train_ds.idx2label,  # –∏–ª–∏ —Å–≤–æ–π —Å–ª–æ–≤–∞—Ä—å\n",
    "        model_name=model_name,\n",
    "        save_dir=save_dir,\n",
    "        img_id=idx\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name, class_map in result_classmaps.items():\n",
    "    uniques, counts = np.unique(class_map, return_counts=True)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for idx, cnt in zip(uniques, counts):\n",
    "        print(f\"  {train_ds.idx2label[idx]}: {cnt} –ø–∞—Ç—á–µ–π\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
