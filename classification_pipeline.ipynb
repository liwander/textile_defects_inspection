{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "requests\n",
    "tqdm>=4.65.0\n",
    "torch>=2.0.0\n",
    "# torchvision>=0.14.0\n",
    "opencv-python\n",
    "numpy>=1.23.0\n",
    "timm>=0.6.13\n",
    "# tensorboard>=2.13.0\n",
    "albumentations>=1.4.0\n",
    "# segmentation-models-pytorch>=0.3.3\n",
    "scikit-learn>=1.1.0\n",
    "matplotlib>=3.5.0\n",
    "# transformers>=4.31.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U -q pip\n",
    "! pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Настройки обучения для классификации ---\n",
    "CONFIG = {\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 2,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-3,\n",
    "    'early_stop_patience': 10,\n",
    "    'dataroot': './aitex_data/extracted',\n",
    "    'log_dir': 'runs/classification_experiment',   # изменил для классификации\n",
    "    'resume': False\n",
    "}\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "# Обнови: для классификации нужны num_classes (не classes)\n",
    "NUM_CLASSES = 12 + 1  # укажи реально (обычно ~12 для дефектов в AITEX)\n",
    "\n",
    "MODELS = {\n",
    "    \"beit_base_patch16_224\": lambda: timm.create_model(\n",
    "        \"beit_base_patch16_224\",\n",
    "        pretrained=True,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        in_chans=3,\n",
    "        drop_rate=0.3,          # <--- Dropout после MLP\n",
    "        drop_path_rate=0.1      # <--- DropPath между блоками\n",
    "    ),\n",
    "    # \"convnext_base\": lambda: timm.create_model(\n",
    "    #     \"convnext_base\",\n",
    "    #     pretrained=True,\n",
    "    #     num_classes=NUM_CLASSES,\n",
    "    #     in_chans=3,\n",
    "    #     drop_path_rate=0.1      # только DropPath\n",
    "    # ),\n",
    "    # \"resnet\": lambda: timm.create_model(\n",
    "    #     \"resnet50\",\n",
    "    #     pretrained=True,\n",
    "    #     num_classes=NUM_CLASSES,\n",
    "    #     in_chans=3\n",
    "    #     # Dropout не используется\n",
    "    # ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def find_max_batch_size(\n",
    "#     model_fn,\n",
    "#     device='cuda',\n",
    "#     image_size=(224, 224),\n",
    "#     max_test=512,\n",
    "#     num_classes=13,\n",
    "#     step=4\n",
    "# ):\n",
    "#     print(f\"\\n=== Поиск максимального batch_size для {model_fn.__name__ if hasattr(model_fn, '__name__') else model_fn} ===\")\n",
    "#     batch_size = step\n",
    "#     last_ok = 0\n",
    "#     model = model_fn().to(device)\n",
    "#     model.eval()\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "\n",
    "#     tried = []\n",
    "#     total_attempts = (max_test // step)\n",
    "#     pbar = tqdm(total=total_attempts, desc='Подбор batch_size', ncols=100)\n",
    "#     while batch_size <= max_test:\n",
    "#         try:\n",
    "#             dummy = torch.randn(batch_size, 3, image_size[0], image_size[1]).to(device)\n",
    "#             with torch.no_grad():\n",
    "#                 out = model(dummy)\n",
    "#             last_ok = batch_size\n",
    "#             tried.append(batch_size)\n",
    "#             batch_size += step\n",
    "#             del dummy, out\n",
    "#             torch.cuda.empty_cache()\n",
    "#             gc.collect()\n",
    "#             pbar.update(1)\n",
    "#         except RuntimeError as e:\n",
    "#             pbar.close()\n",
    "#             if 'out of memory' in str(e):\n",
    "#                 print(f\"\\nOOM at batch_size={batch_size}. Last OK: {last_ok}\")\n",
    "#                 break\n",
    "#             else:\n",
    "#                 print(f\"\\nError at batch_size={batch_size}: {e}\")\n",
    "#                 break\n",
    "#     pbar.close()\n",
    "#     del model\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "#     print(f\"Максимальный batch_size: {last_ok} (для image_size={image_size})\")\n",
    "#     return last_ok\n",
    "\n",
    "# # Пример: для всех моделей\n",
    "# for name, model_fn in MODELS.items():\n",
    "#     print(f\"\\n=== {name} ===\")\n",
    "#     max_bs = find_max_batch_size(model_fn, device='cuda', image_size=(224,224), step=8)\n",
    "#     print(f\"Max batch_size for {name}: {max_bs}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, top_k_accuracy_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "def compute_classification_metrics(y_true, y_pred, y_prob, num_classes, top_k=3):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    metrics[\"precision_macro\"] = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics[\"recall_macro\"] = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics[\"f1_macro\"] = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics[\"precision_micro\"] = precision_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    metrics[\"recall_micro\"] = recall_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    metrics[\"f1_micro\"] = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    metrics[\"confusion_matrix\"] = confusion_matrix(y_true, y_pred)\n",
    "    if y_prob is not None:\n",
    "        metrics[\"top1\"] = top_k_accuracy_score(y_true, y_prob, k=1, labels=list(range(num_classes)))\n",
    "        metrics[\"top3\"] = top_k_accuracy_score(y_true, y_prob, k=min(3, num_classes), labels=list(range(num_classes)))\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f301d04-e66c-4c9f-8de5-dbe2914a8008"
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24403371-53b2-4d52-801a-c2c8e70e884b"
   },
   "source": [
    "## download_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5f9c7e7-768c-4a28-a6df-65cfc48fb7d2",
    "outputId": "51bca206-2f9d-4a8c-e2b4-29e6207b0562"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/nexuswho/aitex-fabric-image-database\"\n",
    "output_dir = Path(\"./aitex_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "zip_path = output_dir / \"aitex.zip\"\n",
    "\n",
    "# Проверка на существование архива\n",
    "if zip_path.exists():\n",
    "    print(f\"[INFO] Архив уже существует по пути: {zip_path}\")\n",
    "else:\n",
    "    print(f\"[INFO] Скачиваем архив из {url}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n",
    "                f.write(chunk)\n",
    "        print(\"[INFO] Скачивание завершено.\")\n",
    "    else:\n",
    "        raise Exception(f\"Ошибка при скачивании: статус {response.status_code}\")\n",
    "\n",
    "# Распаковка архива\n",
    "extract_dir = output_dir / \"extracted\"\n",
    "if not extract_dir.exists():\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"[INFO] Архив успешно распакован в {extract_dir}\")\n",
    "else:\n",
    "    print(f\"[INFO] Архив уже был распакован в {extract_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQ7TjMBbXK_W"
   },
   "source": [
    "## remove_image_without_masks¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3d_pjjlXPlU",
    "outputId": "fb355904-d0a4-4519-b64d-11269c69470a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_images_without_masks(image_dir, mask_dir, image_suffix=\".png\", mask_suffix=\"_mask.png\"):\n",
    "    \"\"\"\n",
    "    Удаляет изображения, для которых отсутствует маска.\n",
    "    \"\"\"\n",
    "    removed = 0\n",
    "    for img_name in os.listdir(image_dir):\n",
    "        if not img_name.endswith(image_suffix):\n",
    "            continue\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        mask_name = base_name + mask_suffix\n",
    "        mask_path = os.path.join(mask_dir, mask_name)\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Удаляется {img_path} (маска {mask_name} не найдена)\")\n",
    "            os.remove(img_path)\n",
    "            removed += 1\n",
    "    print(f\"Удалено изображений без масок: {removed}\")\n",
    "\n",
    "# Пример вызова:\n",
    "remove_images_without_masks(\n",
    "    image_dir=\"./aitex_data/extracted/Defect_images\",\n",
    "    mask_dir=\"./aitex_data/extracted/Mask_images\"\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_and_save_random_image_with_mask(\n",
    "    image_dir, mask_dir,\n",
    "    image_suffix=\".png\", mask_suffix=\"_mask.png\",\n",
    "    save_dir=\"./random_samples\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Выводит и сохраняет случайное изображение и маску.\n",
    "    Картинки выводятся по вертикали (2 строки), сохраняются по отдельности.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith(image_suffix)]\n",
    "    if not image_files:\n",
    "        print(\"Нет изображений в директории.\")\n",
    "        return\n",
    "\n",
    "    img_name = random.choice(image_files)\n",
    "    base_name = os.path.splitext(img_name)[0]\n",
    "    mask_name = base_name + mask_suffix\n",
    "\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    mask_path = os.path.join(mask_dir, mask_name)\n",
    "\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"Маска для {img_name} не найдена: {mask_path}\")\n",
    "        return\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Визуализация по вертикали\n",
    "    plt.figure(figsize=(6, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(f\"Изображение: {img_name}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title(f\"Маска: {mask_name}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Сохранение файлов отдельно\n",
    "    img_save_path = os.path.join(save_dir, f\"{base_name}_image.png\")\n",
    "    mask_save_path = os.path.join(save_dir, f\"{base_name}_mask.png\")\n",
    "    cv2.imwrite(img_save_path, img)\n",
    "    cv2.imwrite(mask_save_path, mask)\n",
    "    print(f\"Сохранено изображение: {img_save_path}\")\n",
    "    print(f\"Сохранена маска: {mask_save_path}\")\n",
    "\n",
    "# Пример вызова:\n",
    "show_and_save_random_image_with_mask(\n",
    "    image_dir=\"./aitex_data/extracted/Defect_images\",\n",
    "    mask_dir=\"./aitex_data/extracted/Mask_images\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "SRC_MSK_DIR = Path(\"./aitex_data/extracted/Mask_images\")\n",
    "\n",
    "min_pixels = None\n",
    "max_pixels = 0\n",
    "pixels_list = []\n",
    "\n",
    "for mask_path in SRC_MSK_DIR.glob(\"*.png\"):\n",
    "    msk = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if msk is None:\n",
    "        continue\n",
    "    num = int((msk > 0).sum())\n",
    "    if num > 0:\n",
    "        pixels_list.append(num)\n",
    "        if min_pixels is None or num < min_pixels:\n",
    "            min_pixels = num\n",
    "        if num > max_pixels:\n",
    "            max_pixels = num\n",
    "\n",
    "print(f\"Минимальное количество пикселей дефекта в одной маске: {min_pixels}\")\n",
    "print(f\"Максимальное: {max_pixels}\")\n",
    "print(f\"Медианное: {np.median(pixels_list)}\")\n",
    "print(f\"Гистограмма по всем изображениям:\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(pixels_list, bins=30)\n",
    "plt.xlabel(\"Дефектных пикселей на маске\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSsXI-e0SWx2"
   },
   "source": [
    "## slice_to_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JeXy3qNSW8E",
    "outputId": "074b13a5-edcd-4632-ea7c-830dc8ba1e02"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Метки дефектов ---\n",
    "DEFECT_LABELS = {\n",
    "    '000': 'No defect',\n",
    "    '002': 'Broken end',\n",
    "    '006': 'Broken yarn',\n",
    "    '010': 'Broken pick',\n",
    "    '016': 'Weft curling',\n",
    "    '019': 'Fuzzyball',\n",
    "    '022': 'Cut selvage',\n",
    "    '023': 'Crease',\n",
    "    '025': 'Warp ball',\n",
    "    '027': 'Knots',\n",
    "    '029': 'Contamination',\n",
    "    '030': 'Nep',\n",
    "    '036': 'Weft crack'\n",
    "}\n",
    "\n",
    "# --- Параметры нарезки ---\n",
    "SRC_IMG_DIR = Path(\"./aitex_data/extracted/Defect_images\")\n",
    "SRC_MSK_DIR = Path(\"./aitex_data/extracted/Mask_images\")\n",
    "DST_IMG_DIR = Path(\"./aitex_patches/images\")\n",
    "DST_MSK_DIR = Path(\"./aitex_patches/masks\")\n",
    "\n",
    "PATCH_W = PATCH_H = 224\n",
    "STRIDE_W = STRIDE_H = (256 - 224)\n",
    "# MIN_DEFECT_FRAC = 0.005       # минимальная доля дефекта\n",
    "MIN_DEFECT_PIXELS = 9 \n",
    "KEEP_NEG = 0.05\n",
    "\n",
    "DST_IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DST_MSK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "PATCH_AREA = PATCH_W * PATCH_H\n",
    "\n",
    "def has_large_defect(mask, min_size=20):\n",
    "    num_labels, _, stats, _ = cv2.connectedComponentsWithStats((mask > 0).astype(np.uint8))\n",
    "    for i in range(1, num_labels):  # 0 — фон\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for img_path in tqdm(sorted(SRC_IMG_DIR.glob(\"*.png\")), desc=\"Cropping AITEX (grid)\"):\n",
    "    mask_path = SRC_MSK_DIR / img_path.name.replace(\".png\", \"_mask.png\")\n",
    "    img = cv2.imread(str(img_path))\n",
    "    msk = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None or msk is None:\n",
    "        print(f\"❌  Пропуск {img_path.name} (файла нет)\")\n",
    "        continue\n",
    "\n",
    "    msk_bin = (msk > 0).astype(np.uint8)\n",
    "    orig_defect_code_str = img_path.stem.split('_')[1]\n",
    "    orig_defect_code = int(orig_defect_code_str)\n",
    "    orig_defect_label = DEFECT_LABELS.get(orig_defect_code_str, \"Unknown\")\n",
    "\n",
    "    # ДВА ЦИКЛА: по y и по x\n",
    "    for y in range(0, img.shape[0] - PATCH_H + 1, STRIDE_H):\n",
    "        for x in range(0, img.shape[1] - PATCH_W + 1, STRIDE_W):\n",
    "            img_crop = img[y:y+PATCH_H, x:x+PATCH_W]\n",
    "            msk_crop = msk_bin[y:y+PATCH_H, x:x+PATCH_W]\n",
    "            pos_pix = int(msk_crop.sum())\n",
    "            defect_frac = pos_pix / PATCH_AREA\n",
    "\n",
    "            # Комбинированный фильтр\n",
    "            # is_defective = (defect_frac >= MIN_DEFECT_FRAC) or (pos_pix >= MIN_DEFECT_PIXELS)\n",
    "\n",
    "            is_defective = pos_pix >= MIN_DEFECT_PIXELS\n",
    "\n",
    "            \n",
    "            patch_defect_code = orig_defect_code\n",
    "            patch_defect_label = orig_defect_label\n",
    "\n",
    "            # Если патч \"чистый\", переопределяем метку\n",
    "            if not is_defective or not has_large_defect(msk_crop, min_size=20):\n",
    "                if np.random.rand() > KEEP_NEG:\n",
    "                    continue\n",
    "                patch_defect_code = 0\n",
    "                patch_defect_label = DEFECT_LABELS['000']\n",
    "\n",
    "            suffix = f\"x{x:04d}_y{y:04d}\"\n",
    "            fname  = f\"{img_path.stem}_{suffix}.png\"\n",
    "            cv2.imwrite(str(DST_IMG_DIR / fname), img_crop)\n",
    "            cv2.imwrite(str(DST_MSK_DIR / fname), msk_crop * 255)\n",
    "            rows.append((fname, patch_defect_code, patch_defect_label))\n",
    "\n",
    "# --- Сохраняем CSV с метками ---\n",
    "label_path = Path(\"./aitex_patches/patch_labels.csv\")\n",
    "label_df = pd.DataFrame(rows, columns=[\"file\", \"defect_code\", \"defect_label\"])\n",
    "label_df.to_csv(label_path, index=False)\n",
    "print(\"📝  Saved\", len(rows), \"patch labels →\", label_path)\n",
    "print(\"✅  Нарезка патчей завершена.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./aitex_patches/patch_labels.csv')\n",
    "has_defect = df[df['defect_label'] != 'No defect']\n",
    "no_defect  = df[df['defect_label'] == 'No defect']\n",
    "\n",
    "print(f\"Дефектных патчей: {len(has_defect)}\")\n",
    "print(f\"Чистых патчей: {len(no_defect)}\")\n",
    "\n",
    "desired_ratio = 1.0  # например, 1:1\n",
    "n_defect = len(has_defect)\n",
    "n_no_defect = min(int(n_defect * desired_ratio), len(no_defect))\n",
    "\n",
    "no_defect_sampled = no_defect.sample(n=n_no_defect, random_state=42)\n",
    "df_balanced = pd.concat([has_defect, no_defect_sampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "balanced_label_path = './aitex_patches/patch_labels_balanced.csv'\n",
    "df_balanced.to_csv(balanced_label_path, index=False)\n",
    "print(f\"Balanced CSV saved: {balanced_label_path}\")\n",
    "\n",
    "# --- Новый вывод ---\n",
    "summary = df_balanced['defect_label'].value_counts().reset_index()\n",
    "summary.columns = ['defect_label', 'num_patches']\n",
    "summary['percentage'] = (summary['num_patches'] / summary['num_patches'].sum() * 100).round(2)\n",
    "\n",
    "print(\"\\n=== Patch distribution (balanced) ===\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "PATCH_LABEL_PATH = balanced_label_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_patches_with_masks_and_labels(\n",
    "    img_dir,\n",
    "    mask_dir,\n",
    "    csv_path,\n",
    "    min_defect_pixels=MIN_DEFECT_PIXELS,\n",
    "    n_pos=6,\n",
    "    n_neg=6\n",
    "):\n",
    "    \"\"\"\n",
    "    Показывает патчи с дефектом и без дефекта:\n",
    "    - Оригинал (RGB)\n",
    "    - Маска (отдельно)\n",
    "    - Наложение маски (Mask Overlay)\n",
    "    В заголовке — статус (DEFECT/CLEAN) и класс дефекта.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    pos_samples, neg_samples = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        mask_path = Path(mask_dir) / row['file']\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            continue\n",
    "        defect_pixels = (mask > 0).sum()\n",
    "        info = (row['file'], row['defect_label'])\n",
    "        if defect_pixels >= min_defect_pixels:\n",
    "            pos_samples.append(info)\n",
    "        else:\n",
    "            neg_samples.append(info)\n",
    "\n",
    "    pos_samples = random.sample(pos_samples, min(n_pos, len(pos_samples)))\n",
    "    neg_samples = random.sample(neg_samples, min(n_neg, len(neg_samples)))\n",
    "    all_samples = [(fname, \"DEFECT\", label) for fname, label in pos_samples] + \\\n",
    "                  [(fname, \"CLEAN\", label) for fname, label in neg_samples]\n",
    "\n",
    "    plt.figure(figsize=(len(all_samples) * 4, 10))\n",
    "    for i, (fname, status, defect_label) in enumerate(all_samples):\n",
    "        img = cv2.imread(str(Path(img_dir) / fname))\n",
    "        mask = cv2.imread(str(Path(mask_dir) / fname), cv2.IMREAD_GRAYSCALE)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 1. Исходное изображение\n",
    "        plt.subplot(3, len(all_samples), i + 1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(f\"{status}\\n{defect_label}\\n{fname}\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 2. Маска (отдельно)\n",
    "        plt.subplot(3, len(all_samples), len(all_samples) + i + 1)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.title(\"Mask\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 3. Наложение маски\n",
    "        plt.subplot(3, len(all_samples), 2 * len(all_samples) + i + 1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.imshow(mask, cmap='Reds', alpha=0.5)\n",
    "        plt.title(\"Overlay\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Запуск визуализации ---\n",
    "visualize_patches_with_masks_and_labels(\n",
    "    img_dir=DST_IMG_DIR,\n",
    "    mask_dir=DST_MSK_DIR,\n",
    "    csv_path=PATCH_LABEL_PATH,\n",
    "    min_defect_pixels=MIN_DEFECT_PIXELS,  # ключевое отличие!\n",
    "    n_pos=3,\n",
    "    n_neg=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Пути к данным\n",
    "PATCH_LABEL_PATH = './aitex_patches/patch_labels_balanced.csv'  # или твой итоговый путь\n",
    "\n",
    "# Чтение меток\n",
    "df = pd.read_csv(PATCH_LABEL_PATH)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5603c4bf-2c6b-41e6-a789-5b3b4afb6fb1"
   },
   "source": [
    "## augmenations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_strong_classification_augmentations(image_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Сильные аугментации для train.\n",
    "    Устраняем предупреждения, оставляя только поддерживаемые параметры.\n",
    "    \"\"\"\n",
    "    ops = [\n",
    "        A.Resize(int(image_size[0]*1.1), int(image_size[1]*1.1)),\n",
    "        A.RandomCrop(*image_size, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Affine(\n",
    "            scale=(0.85, 1.15),\n",
    "            translate_percent=0.15,\n",
    "            rotate=(-30, 30),\n",
    "            shear=(-12, 12),\n",
    "            p=0.7\n",
    "        ),\n",
    "        A.ElasticTransform(p=0.25),  # убраны неподдерживаемые alpha_affine\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.2),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
    "        A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=20, val_shift_limit=15, p=0.4),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "        A.GaussNoise(p=0.4),          # var_limit по умолчанию\n",
    "        A.GaussianBlur(blur_limit=(3, 9), p=0.3),\n",
    "        A.CoarseDropout(p=0.4),        # default параметры\n",
    "    ]\n",
    "\n",
    "    # Добавляем GridMask, если доступен (albumentations>=1.2.0)\n",
    "    if hasattr(A, 'GridMask'):\n",
    "        ops.append(A.GridMask(num_grid=(3, 7), rotate=15, p=0.3))\n",
    "\n",
    "    # Нормализация и перевод в тензор\n",
    "    ops.extend([\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    return A.Compose(ops)\n",
    "\n",
    "\n",
    "def get_val_classification_augmentations(image_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Лёгкие аугментации для валидации/теста.\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(*image_size),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9564655-5c04-45e3-af7b-c6a48c992e00"
   },
   "source": [
    "## dataset_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- твой кастомный класс PatchDataset с copy-paste ---\n",
    "import random\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Классификационный датасет патчей с class-aware Copy-Paste.\n",
    "    Возвращает: (img_tensor, class_idx)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        img_dir: str,\n",
    "        transform,\n",
    "        copy_paste_prob: float = 0.3,\n",
    "        class_copy_paste: bool = True,\n",
    "        random_state: int = 42\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.copy_paste_prob = copy_paste_prob\n",
    "        self.class_copy_paste = class_copy_paste\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "\n",
    "        # mapping label ↔ idx\n",
    "        labels = sorted(self.df['defect_label'].unique())\n",
    "        self.label2idx = {lbl: i for i, lbl in enumerate(labels)}\n",
    "        self.idx2label = {i: lbl for lbl, i in self.label2idx.items()}\n",
    "\n",
    "        # pool дефектных файлов и подсчет дефицита до медианы\n",
    "        codes = self.df['defect_code'].values\n",
    "        files = self.df['file'].values\n",
    "        defect_mask = codes != 0\n",
    "        defect_codes = codes[defect_mask]\n",
    "        defect_files = files[defect_mask]\n",
    "\n",
    "        cnt = pd.Series(defect_codes).value_counts().to_dict()\n",
    "        median = int(np.median(list(cnt.values()))) or 1\n",
    "        deficit = {c: max(0, median - n) for c, n in cnt.items()}\n",
    "        total_def = sum(deficit.values())\n",
    "        self.class_probs = {c: d/total_def for c, d in deficit.items()} if total_def>0 else {}\n",
    "        self.defect_pool = list(zip(defect_files, defect_codes))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        fname = row['file']\n",
    "        code = int(row['defect_code'])\n",
    "        img = cv2.cvtColor(cv2.imread(str(self.img_dir / fname)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Copy-Paste для чистых патчей\n",
    "        if code == 0 and self.defect_pool and self.rng.rand() < self.copy_paste_prob:\n",
    "            # выбор класса-донор\n",
    "            if self.class_copy_paste and self.class_probs:\n",
    "                codes, probs = zip(*self.class_probs.items())\n",
    "                sel_code = int(self.rng.choice(codes, p=probs))\n",
    "                candidates = [f for f, c in self.defect_pool if c == sel_code]\n",
    "            else:\n",
    "                candidates = [f for f, _ in self.defect_pool]\n",
    "            donor = self.rng.choice(candidates)\n",
    "            donor_img = cv2.cvtColor(cv2.imread(str(self.img_dir / donor)), cv2.COLOR_BGR2RGB)\n",
    "            # простой маскированный встав: по пиксельному отличию\n",
    "            mask = (donor_img != img).any(axis=2).astype(np.uint8)\n",
    "            for ch in range(3):\n",
    "                img[:, :, ch] = donor_img[:, :, ch] * mask + img[:, :, ch] * (1-mask)\n",
    "            code = int([c for f, c in self.defect_pool if f == donor][0])\n",
    "\n",
    "        # применение аугментаций и нормализация\n",
    "        img = self.transform(image=img)['image']\n",
    "        label = self.label2idx[row['defect_label']]\n",
    "        return img, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset creation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_train_to_median(train_df, label_col='defect_code', random_state=42):\n",
    "    counts = train_df[label_col].value_counts()\n",
    "    median = int(counts.median())\n",
    "    upsampled = []\n",
    "    for label, cnt in counts.items():\n",
    "        df_label = train_df[train_df[label_col] == label]\n",
    "        if cnt < median:\n",
    "            n_more = median - cnt\n",
    "            sampled = df_label.sample(n=n_more, replace=True, random_state=random_state)\n",
    "            upsampled.append(sampled)\n",
    "    if upsampled:\n",
    "        train_df = pd.concat([train_df] + upsampled).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- prepare_datasets для классификации патчей ---\n",
    "def prepare_datasets(\n",
    "    patch_label_path: str,\n",
    "    img_dir: str,\n",
    "    test_size: float = 0.05,\n",
    "    val_size: float = 0.1,\n",
    "    batch_size: int = 16,\n",
    "    num_workers: int = 4,\n",
    "    random_state: int = 42,\n",
    "    image_size: tuple = (224, 224),\n",
    "    train_aug_fn=None,\n",
    "    val_aug_fn=None,\n",
    "    copy_paste_prob: float = 0.3\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Возвращает train_ds, val_ds, test_ds (PatchDataset) с copy-paste для train.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(patch_label_path)\n",
    "\n",
    "    # stratified split\n",
    "    train_files, test_files = train_test_split(\n",
    "        df['file'], test_size=test_size,\n",
    "        stratify=df['defect_code'], random_state=random_state\n",
    "    )\n",
    "    train_files, val_files = train_test_split(\n",
    "        train_files, test_size=val_size,\n",
    "        stratify=df[df['file'].isin(train_files)]['defect_code'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    train_df = df[df['file'].isin(train_files)].reset_index(drop=True)\n",
    "    val_df = df[df['file'].isin(val_files)].reset_index(drop=True)\n",
    "    test_df = df[df['file'].isin(test_files)].reset_index(drop=True)\n",
    "\n",
    "    # upsamples до медианы\n",
    "    # train_df = upsample_train_to_median(train_df, label_col='defect_code', random_state=random_state)\n",
    "    print(\"Train class distribution\")\n",
    "    print(train_df['defect_code'].value_counts())\n",
    "\n",
    "    # transforms\n",
    "    train_transform = train_aug_fn or get_strong_classification_augmentations(image_size)\n",
    "    val_transform = val_aug_fn or get_val_classification_augmentations(image_size)\n",
    "\n",
    "    # datasets\n",
    "    train_ds = PatchDataset(\n",
    "        train_df, img_dir,\n",
    "        transform=train_transform,\n",
    "        copy_paste_prob=copy_paste_prob,\n",
    "        class_copy_paste=True,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    val_ds = PatchDataset(\n",
    "        val_df, img_dir,\n",
    "        transform=val_transform,\n",
    "        copy_paste_prob=0.0\n",
    "    )\n",
    "    test_ds = PatchDataset(\n",
    "        test_df, img_dir,\n",
    "        transform=val_transform,\n",
    "        copy_paste_prob=0.0\n",
    "    )\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader creation helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_classification_dataloaders(\n",
    "    train_ds, val_ds, test_ds,\n",
    "    batch_size: int = 16,\n",
    "    num_workers: int = 4\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Оборачивает датасеты в DataLoader'ы с правильными параметрами.\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Пример использования ===\n",
    "PATCH_LABEL_PATH = './aitex_patches/patch_labels_balanced.csv'\n",
    "IMG_DIR = './aitex_patches/images'\n",
    "MSK_DIR = './aitex_patches/masks'\n",
    "\n",
    "train_ds, val_ds, test_ds = prepare_datasets(\n",
    "    patch_label_path=PATCH_LABEL_PATH,\n",
    "    img_dir=IMG_DIR,\n",
    "    # msk_dir=MSK_DIR,\n",
    "    test_size=0.05,\n",
    "    val_size=0.1,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    random_state=42,\n",
    "    image_size=(PATCH_H, PATCH_W),\n",
    "    train_aug_fn=get_strong_classification_augmentations((PATCH_H, PATCH_W)),\n",
    "    val_aug_fn=get_val_classification_augmentations((PATCH_H, PATCH_W)),\n",
    "    copy_paste_prob=0.8\n",
    ")\n",
    "\n",
    "print(\"label2idx:\", train_ds.label2idx)\n",
    "print(\"idx2label:\", train_ds.idx2label)\n",
    "print(\"Всего классов:\", len(train_ds.label2idx))\n",
    "\n",
    "train_loader, val_loader, test_loader = get_classification_dataloaders(\n",
    "    train_ds, val_ds, test_ds,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_weighted_loss(train_ds, smoothing=0.1, device='cuda'):\n",
    "    # Подсчитываем метки из train_ds\n",
    "    train_labels = [label for _, label in train_ds]\n",
    "\n",
    "    # Подсчёт количества каждого класса\n",
    "    class_counts = Counter(train_labels)\n",
    "    num_classes = len(train_ds.label2idx)\n",
    "    total_samples = len(train_labels)\n",
    "\n",
    "    # Подсчитываем веса (обратная частота)\n",
    "    class_weights = np.zeros(num_classes)\n",
    "    for cls_idx in range(num_classes):\n",
    "        cls_count = class_counts.get(cls_idx, 0)\n",
    "        class_weights[cls_idx] = total_samples / (num_classes * cls_count)\n",
    "\n",
    "    # Нормализация весов\n",
    "    class_weights = class_weights / class_weights.sum() * num_classes\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "    # Создаём взвешенную CrossEntropyLoss с label smoothing\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=smoothing)\n",
    "    return loss_fn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def print_class_distribution_from_dataset(dataset, label_names=None, title=\"Train set\"):\n",
    "    \"\"\"\n",
    "    Выводит таблицу распределения патчей по классам для кастомного датасета (классификация или сегментация).\n",
    "    - dataset: экземпляр Dataset (например, PatchClassificationDataset или AITEXPatchDataset)\n",
    "    - label_names: dict для красивых названий классов {idx: name} или {code: name}\n",
    "    - title: заголовок для вывода\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        try:\n",
    "            # Классификация (img, label) или (img, mask, label)\n",
    "            if hasattr(dataset, \"idx2label\"):\n",
    "                # Индекс → строка класса\n",
    "                _, label = dataset[i][:2]\n",
    "                class_label = dataset.idx2label[label]\n",
    "            else:\n",
    "                # Например, (img, mask, code, label)\n",
    "                *_, label = dataset[i]\n",
    "                class_label = label\n",
    "        except Exception:\n",
    "            # Любой fallback\n",
    "            class_label = \"unknown\"\n",
    "        labels.append(class_label)\n",
    "\n",
    "    df = pd.DataFrame({'class_label': labels})\n",
    "    summary = df['class_label'].value_counts().reset_index()\n",
    "    summary.columns = ['class_label', 'num_patches']\n",
    "    summary['percentage'] = (summary['num_patches'] / summary['num_patches'].sum() * 100).round(2)\n",
    "    if label_names:\n",
    "        summary['class_label'] = summary['class_label'].map(label_names).fillna(summary['class_label'])\n",
    "    print(f\"\\n=== Patch distribution in {title} ===\")\n",
    "    print(summary.to_string(index=False))\n",
    "\n",
    "\n",
    "print_class_distribution_from_dataset(train_ds, label_names=DEFECT_LABELS, title=\"Train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:13:36.398507Z",
     "iopub.status.busy": "2025-05-17T08:13:36.397903Z",
     "iopub.status.idle": "2025-05-17T08:13:36.402238Z",
     "shell.execute_reply": "2025-05-17T08:13:36.401567Z",
     "shell.execute_reply.started": "2025-05-17T08:13:36.398482Z"
    }
   },
   "source": [
    "## visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def visualize_classification_dataset_grid(dataset, num_samples=6, label_names=None):\n",
    "    \"\"\"\n",
    "    Визуализация классификационного датасета:\n",
    "    - Горизонтально — разные патчи/изображения (num_samples)\n",
    "    - Только 1 ряд: изображение\n",
    "    - В заголовке: код и (при наличии) красивый лейбл класса\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    plt.figure(figsize=(num_samples * 4, 4))\n",
    "\n",
    "    for col, idx in enumerate(indices):\n",
    "        sample = dataset[idx]\n",
    "        # Ожидается (img, class_code, class_label) или (img, class_code)\n",
    "        if len(sample) == 3:\n",
    "            image, code, label = sample\n",
    "        elif len(sample) == 2:\n",
    "            image, code = sample\n",
    "            label = str(code)\n",
    "        else:\n",
    "            image = sample[0]\n",
    "            code = None\n",
    "            label = \"unknown\"\n",
    "\n",
    "        # Красивое имя класса\n",
    "        if label_names is not None:\n",
    "            class_name = label_names.get(str(code), str(label))\n",
    "        else:\n",
    "            class_name = str(label)\n",
    "\n",
    "        title = f\"Code: {code}\\nLabel: {class_name}\"\n",
    "\n",
    "        # Денормализация если тензор\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            rgb = image[:3].permute(1, 2, 0).cpu().numpy()\n",
    "            rgb = (rgb * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)\n",
    "        else:\n",
    "            rgb = image\n",
    "\n",
    "        plt.subplot(1, num_samples, col + 1)\n",
    "        plt.imshow(rgb)\n",
    "        plt.title(title, fontsize=11)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_classification_dataset_grid(train_ds, num_samples=8, label_names=DEFECT_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d1ff18c-c131-45de-9398-aede203360ae"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3255ae5-59eb-4535-8ef5-ac60786a3d78"
   },
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf07f1c4-b824-4326-83d7-182705364d64"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data.mixup import Mixup\n",
    "\n",
    "# --- Настройка MixUp + CutMix ---\n",
    "mixup_fn = Mixup(\n",
    "    mixup_alpha=0.4,        # \"смешивание\" — типовое значение\n",
    "    cutmix_alpha=1.0,       # CutMix тоже включён (обычно 0.5-1.0, можно поиграться)\n",
    "    label_smoothing=0.1,    # обязательно, если у тебя и так стоит — можно чуть снизить\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "753ae338-0818-4155-a3a1-0f41f531c633"
   },
   "source": [
    "#### train_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbe9d1a7-7977-4887-9cdb-49631ed48270"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from timm.utils import ModelEmaV2\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model, train_loader, optimizer, loss_fn, scaler,\n",
    "    device, epoch, model_name, num_classes,\n",
    "    mixup_fn=None, ema=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Одна эпоха обучения с опциональным MixUp/CutMix и обновлением EMA.\n",
    "    Возвращает метрики для train.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_probs, all_targets = [], [], []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_loader, desc=f\"Train {epoch}\")):\n",
    "        images, labels = batch[:2]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # MIXUP / CUTMIX\n",
    "        if mixup_fn:\n",
    "            images, labels = mixup_fn(images, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(enabled=(device.type=='cuda')):\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # backward + step\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # EMA update\n",
    "        if ema is not None:\n",
    "            ema.update(model)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # accumulate predictions\n",
    "        probs = torch.softmax(outputs.detach(), dim=1).cpu().numpy()\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        all_preds.append(preds)\n",
    "        all_probs.append(probs)\n",
    "        if labels.dtype == torch.float32:\n",
    "            all_targets.append(labels.argmax(dim=1).cpu().numpy())\n",
    "        else:\n",
    "            all_targets.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_targets)\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_prob = np.concatenate(all_probs)\n",
    "\n",
    "    metrics = compute_classification_metrics(y_true, y_pred, y_prob, num_classes)\n",
    "    metrics['loss'] = running_loss / len(train_loader)\n",
    "    print(f\"[{model_name}] Train epoch {epoch}: {metrics}\")\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d138719-faf4-4542-9e15-d2a65f9ee065"
   },
   "source": [
    "#### validate_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4ea0489-92c9-468b-804a-fb298be2ac67"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate_epoch(\n",
    "    model, val_loader, device, epoch, model_name, num_classes\n",
    "):\n",
    "    \"\"\"\n",
    "    Одна эпоха валидации на переданной модели (обычно EMA).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_probs, all_targets = [], [], []\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(tqdm(val_loader, desc=f\"Val  {epoch}\")):\n",
    "            images, labels = batch[:2]\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs.cpu(), dim=1).numpy()\n",
    "            preds = np.argmax(probs, axis=1)\n",
    "            all_preds.append(preds)\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_targets)\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_prob = np.concatenate(all_probs)\n",
    "\n",
    "    metrics = compute_classification_metrics(y_true, y_pred, y_prob, num_classes)\n",
    "    metrics['loss'] = running_loss / len(val_loader)\n",
    "    print(f\"[{model_name}] Val epoch {epoch}: {metrics}\")\n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce566e89-fcb2-4fc9-b633-7f40426ae8a0"
   },
   "source": [
    "### train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf9f600f-462d-4d7f-9edb-9dc8f1f6bb20"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(\n",
    "    model, optimizer, scheduler,\n",
    "    train_loader, val_loader,\n",
    "    loss_fn, device, scaler,\n",
    "    num_classes,\n",
    "    num_epochs=50, early_stop_patience=5,\n",
    "    model_name='model', mixup_fn=None,\n",
    "    ema_decay: float = 0.9999\n",
    "):\n",
    "    \"\"\"\n",
    "    Основная петля обучения с EMA, scheduler и early-stopping по macro-F1.\n",
    "    Возвращает истории train и val.\n",
    "    \"\"\"\n",
    "    # Инициализация EMA\n",
    "    ema = ModelEmaV2(model, decay=ema_decay, device=device)\n",
    "    best_f1 = 0.0\n",
    "    counter = 0\n",
    "    train_history, val_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train\n",
    "        train_metrics = train_epoch(\n",
    "            model, train_loader, optimizer, loss_fn, scaler,\n",
    "            device, epoch, model_name, num_classes,\n",
    "            mixup_fn=mixup_fn, ema=ema\n",
    "        )\n",
    "        # val на EMA-модели\n",
    "        ema_model = ema.module\n",
    "        val_metrics = validate_epoch(\n",
    "            ema_model, val_loader, device, epoch, model_name, num_classes\n",
    "        )\n",
    "\n",
    "        scheduler.step(val_metrics['f1_macro'])\n",
    "        train_history.append(train_metrics)\n",
    "        val_history.append(val_metrics)\n",
    "\n",
    "        # early stopping + сохранение лучших\n",
    "        if val_metrics['f1_macro'] > best_f1:\n",
    "            best_f1 = val_metrics['f1_macro']\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_{model_name}.pth\")\n",
    "            ema_state = ema.state_dict()\n",
    "            torch.save(ema_state, f\"ema_{model_name}.pth\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= early_stop_patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        print(f\"Epoch {epoch}: Train F1(macro)={train_metrics['f1_macro']:.4f}  Val F1(macro)={val_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "    print(f\"Best Val F1(macro): {best_f1:.4f}\")\n",
    "    return train_history, val_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(train_history, val_history, model_name, save_path=None):\n",
    "    keys = ['loss', 'accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'top1', 'top3']\n",
    "    n_keys = len(keys)\n",
    "    n_cols = 3  # Можно сделать 4 — будет более растянуто\n",
    "    n_rows = math.ceil(n_keys / n_cols)\n",
    "    plt.figure(figsize=(n_cols * 6, n_rows * 4))\n",
    "    for idx, key in enumerate(keys, 1):\n",
    "        plt.subplot(n_rows, n_cols, idx)\n",
    "        train_vals = [m.get(key, 0) for m in train_history]\n",
    "        val_vals = [m.get(key, 0) for m in val_history]\n",
    "        plt.plot(train_vals, label=f\"Train {key}\")\n",
    "        plt.plot(val_vals, label=f\"Val {key}\")\n",
    "        plt.title(f\"{model_name}: {key}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ae365e2-c328-4044-8043-7e795ff63d0d"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_single_model(\n",
    "    model_name, model_fn,\n",
    "    train_loader, val_loader,\n",
    "    config, num_classes,\n",
    "    mixup_fn=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Тренирует модель с EMA, OneCycleLR и weighted loss + smoothing.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model_fn().to(device)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config['learning_rate'],\n",
    "        total_steps=len(train_loader)*config['num_epochs'],\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0\n",
    "    )\n",
    "    # Взвешенный loss + smoothing\n",
    "    loss_fn = get_weighted_loss(train_ds, smoothing=config.get('smoothing',0.1), device=device)\n",
    "    scaler = GradScaler(enabled=(device.type=='cuda'))\n",
    "\n",
    "    return train_loop(\n",
    "        model, optimizer, scheduler,\n",
    "        train_loader, val_loader,\n",
    "        loss_fn, device, scaler,\n",
    "        num_classes,\n",
    "        num_epochs=config['num_epochs'],\n",
    "        early_stop_patience=config['early_stop_patience'],\n",
    "        model_name=model_name,\n",
    "        mixup_fn=mixup_fn,\n",
    "        ema_decay=config.get('ema_decay',0.9999)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0014b2c-1b67-4a7f-aa97-281f74a127cf"
   },
   "source": [
    "## train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:31:34.969449Z",
     "iopub.status.busy": "2025-05-17T08:31:34.968855Z",
     "iopub.status.idle": "2025-05-17T08:31:34.972959Z",
     "shell.execute_reply": "2025-05-17T08:31:34.972253Z",
     "shell.execute_reply.started": "2025-05-17T08:31:34.969421Z"
    }
   },
   "source": [
    "## run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def train_all_models(models_dict, train_loader, val_loader, config, num_classes, mixup_fn=None):\n",
    "    for name, model_fn in models_dict.items():\n",
    "        print(f\"==== Training model: {name} ====\")\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "        train_hist, val_hist = train_single_model(\n",
    "            name, model_fn, train_loader, val_loader, config, num_classes, mixup_fn=mixup_fn\n",
    "        )\n",
    "        plot_metrics(train_hist, val_hist, model_name=name, save_path=f\"metrics_{name}.png\")\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "train_all_models(MODELS, train_loader, val_loader, CONFIG, NUM_CLASSES, mixup_fn=mixup_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e842448e-1511-420a-80ae-604b9906ee7e"
   },
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "613d4e65-8746-43cf-84b5-c2b1500b33f1"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69248cf9-4a14-42ac-a7a3-1078ee5412e4"
   },
   "source": [
    "### tta_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99356348-3504-45cf-a379-fb48203fed90"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def tta_predict_classification(model, images):\n",
    "    \"\"\"\n",
    "    Применяет TTA для классификации: оригинал + горизонтальное отражение.\n",
    "    Возвращает усреднённые logits.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        orig = model(images)\n",
    "        flip_imgs = torch.flip(images, dims=[3])\n",
    "        flip_preds = model(flip_imgs)\n",
    "        # НЕ надо обратно отражать flip_preds для классификации!\n",
    "        # Просто усредняем вероятности/логиты\n",
    "        return (orig + flip_preds) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96c786e1-1cfa-4043-88f9-f4a5693ade51"
   },
   "source": [
    "### visualize_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fb48f84b-6b6d-42b3-ade3-422749fe74e7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def visualize_classification_predictions_tta(\n",
    "    model,\n",
    "    dataloader,\n",
    "    device,\n",
    "    label_names=None,\n",
    "    num_samples=10,\n",
    "    imagenet_norm=True,\n",
    "    model_title=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Визуализирует несколько случайных примеров из даталоадера:\n",
    "    1. Исходное изображение\n",
    "    2. Истинная метка (GT)\n",
    "    3. Предсказанная метка (TTA)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    images_list = []\n",
    "    gt_labels_list = []\n",
    "    pred_labels_list = []\n",
    "    titles = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            # Получаем предсказания c TTA\n",
    "            logits = tta_predict_classification(model, images)\n",
    "            probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "            preds = np.argmax(probs, axis=1)\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            for i in range(batch_size):\n",
    "                if shown >= num_samples:\n",
    "                    break\n",
    "\n",
    "                img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "                if imagenet_norm:\n",
    "                    img = (img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)\n",
    "                gt_idx = labels[i]\n",
    "                pred_idx = preds[i]\n",
    "                gt_name = label_names.get(gt_idx, str(gt_idx)) if label_names else str(gt_idx)\n",
    "                pred_name = label_names.get(pred_idx, str(pred_idx)) if label_names else str(pred_idx)\n",
    "\n",
    "                title = f\"GT: {gt_name}\\nPred: {pred_name}\"\n",
    "                images_list.append(img)\n",
    "                titles.append(title)\n",
    "\n",
    "                shown += 1\n",
    "            if shown >= num_samples:\n",
    "                break\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(num_samples * 3, 4))\n",
    "    if model_title is not None:\n",
    "        plt.suptitle(model_title, fontsize=16, y=1.08)\n",
    "    for col in range(shown):\n",
    "        plt.subplot(1, num_samples, col + 1)\n",
    "        plt.imshow(images_list[col])\n",
    "        plt.title(titles[col], fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "idx2label = train_ds.idx2label  # Или свой словарь {int: str}\n",
    "\n",
    "for model_name in MODELS:\n",
    "    checkpoint_path = f'best_{model_name}.pth'\n",
    "    print(f\"\\n--- Model: {model_name} ---\")\n",
    "    try:\n",
    "        test_model = MODELS[model_name]().to(device)\n",
    "        test_model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        test_model.eval()\n",
    "        \n",
    "        visualize_classification_predictions_tta(\n",
    "            test_model,\n",
    "            dataloader=test_loader,\n",
    "            device=device,\n",
    "            label_names=idx2label,\n",
    "            num_samples=5,\n",
    "            model_title=f\"Model: {model_name}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Could not evaluate {model_name}: {e}\")\n",
    "    finally:\n",
    "        del test_model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb943ece-2f41-4c50-834d-9a1edf782ca1"
   },
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def classification_sanity_check(\n",
    "    train_ds, MODELS, device, target_label=None, num_epochs=20, N=8, idx2label=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Sanity check: быстрое переобучение на одном патче (классификация).\n",
    "    Если target_label не задан — берёт первый попавшийся патч.\n",
    "    Если задан (например, \"No defect\" или \"Broken end\"), берёт первый патч этого класса.\n",
    "    \"\"\"\n",
    "    # 1. Найти патч с нужным классом\n",
    "    idx = None\n",
    "    for i in range(len(train_ds)):\n",
    "        img, label = train_ds[i]\n",
    "        if (target_label is None) or (idx2label and idx2label[label] == target_label):\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        raise RuntimeError(\"Не найден подходящий патч для sanity check!\")\n",
    "    img, label = train_ds[idx]\n",
    "\n",
    "    print(f\"Sanity check: патч класса '{idx2label[label] if idx2label else label}' (индекс {label})\")\n",
    "\n",
    "    # 2. Делаем датасет из N копий этого патча\n",
    "    single_ds = [(img, label)] * N\n",
    "    single_loader = DataLoader(single_ds, batch_size=N, shuffle=True)\n",
    "\n",
    "    # 3. Проверяем все модели\n",
    "    for model_name, model_fn in MODELS.items():\n",
    "        print(f\"\\n==== Sanity check: {model_name} ====\")\n",
    "        model = model_fn().to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        losses, accs = [], []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for img_batch, label_batch in single_loader:\n",
    "                img_batch = img_batch.to(device)\n",
    "                label_batch = label_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(img_batch)\n",
    "                loss = loss_fn(output, label_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Проверка: точность и динамика\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(img_batch)\n",
    "                probs = torch.softmax(output, dim=1)\n",
    "                pred_class = probs.argmax(dim=1).cpu().numpy()\n",
    "                gt_class = label_batch.cpu().numpy()\n",
    "                acc = (pred_class == gt_class).mean()\n",
    "            losses.append(loss.item())\n",
    "            accs.append(acc)\n",
    "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}, Acc = {acc:.3f}, GT: {idx2label[gt_class[0]] if idx2label else gt_class[0]}, Pred: {idx2label[pred_class[0]] if idx2label else pred_class[0]}\")\n",
    "\n",
    "        # Визуализация loss/accuracy\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "        axs[0].plot(losses, label=\"Loss\")\n",
    "        axs[0].set_title(f\"{model_name} Loss\")\n",
    "        axs[1].plot(accs, label=\"Acc\")\n",
    "        axs[1].set_title(f\"{model_name} Accuracy\")\n",
    "        for ax in axs: ax.grid(); ax.set_xlabel('Epoch')\n",
    "        plt.suptitle(f\"Sanity Check: {model_name} — класс '{idx2label[label] if idx2label else label}'\")\n",
    "        plt.show()\n",
    "\n",
    "        # Визуализация самого патча\n",
    "        img_np = img[:3].permute(1,2,0).cpu().numpy() if isinstance(img, torch.Tensor) else img\n",
    "        img_np = (img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0,1)\n",
    "        plt.figure(figsize=(3,3))\n",
    "        plt.imshow(img_np)\n",
    "        plt.title(f\"Class: {idx2label[label] if idx2label else label}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# === Пример запуска ===\n",
    "# Для любого класса (первый попавшийся):\n",
    "classification_sanity_check(\n",
    "    train_ds, MODELS, device,\n",
    "    target_label=None,     # или например \"No defect\"\n",
    "    num_epochs=20, N=8,\n",
    "    idx2label=train_ds.idx2label\n",
    ")\n",
    "\n",
    "# Для \"чистого\" патча (если нужно):\n",
    "classification_sanity_check(\n",
    "    train_ds, MODELS, device,\n",
    "    target_label=\"No defect\",\n",
    "    num_epochs=20, N=8,\n",
    "    idx2label=train_ds.idx2label\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def classification_sanity_check(train_ds, MODELS, device, target_label=None, num_epochs=20, N=8):\n",
    "    \"\"\"\n",
    "    Sanity check: модель должна зафититься на одном и том же патче (классификация).\n",
    "    target_label: если задан, ищет первый патч с этим label.\n",
    "                  Например, для дефектного: target_label != 'No defect'\n",
    "                  Для чистого: target_label == 'No defect'\n",
    "    \"\"\"\n",
    "    # 1. Найти патч по критерию\n",
    "    idx = None\n",
    "    for i in range(len(train_ds)):\n",
    "        img, label = train_ds[i]\n",
    "        if target_label is None or train_ds.idx2label[label] == target_label:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        raise RuntimeError(\"Не найден подходящий патч для sanity check!\")\n",
    "    img, label = train_ds[idx]\n",
    "\n",
    "    # 2. Делаем датасет из N копий одного патча\n",
    "    single_ds = [(img, label)] * N\n",
    "    single_loader = DataLoader(single_ds, batch_size=N, shuffle=True)\n",
    "\n",
    "    for model_name, model_fn in MODELS.items():\n",
    "        print(f\"\\n==== Sanity check: {model_name} ====\")\n",
    "        model = model_fn().to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for img_batch, label_batch in single_loader:\n",
    "                img_batch = img_batch.to(device)\n",
    "                label_batch = label_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(img_batch)\n",
    "                loss = loss_fn(output, label_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Проверка\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(img_batch)\n",
    "                probs = torch.softmax(output, dim=1)\n",
    "                pred_class = probs.argmax(dim=1).cpu().numpy()\n",
    "                gt_class = label_batch.cpu().numpy()\n",
    "                acc = (pred_class == gt_class).mean()\n",
    "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}, Acc = {acc:.3f}, GT: {train_ds.idx2label[gt_class[0]]}, Pred: {train_ds.idx2label[pred_class[0]]}\")\n",
    "\n",
    "        # Визуализация патча\n",
    "        img_np = img[:3].permute(1,2,0).cpu().numpy() if isinstance(img, torch.Tensor) else img\n",
    "        img_np = (img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0,1)\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(img_np)\n",
    "        plt.title(f\"Sanity Check: {model_name}\\nClass: {train_ds.idx2label[label]}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41909dd6-9ae4-4a24-80b3-bac29015e091"
   },
   "outputs": [],
   "source": [
    "classification_sanity_check(train_ds, MODELS, device, target_label='Broken end', num_epochs=20, N=8)\n",
    "# (или target_label != 'No defect', если хочется подобрать именно дефект)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_sanity_check(train_ds, MODELS, device, target_label='No defect', num_epochs=20, N=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def infer_full_image_classification_with_models(\n",
    "    image,\n",
    "    models_dict,\n",
    "    preprocess,\n",
    "    patch_h=224,\n",
    "    patch_w=224,\n",
    "    stride_h=64,\n",
    "    stride_w=64,\n",
    "    device='cuda',\n",
    "    model_names=None,\n",
    "    config=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Для каждого патча исходного изображения получить предсказания классов от всех моделей.\n",
    "    Возвращает dict: {model_name: 2D array of class indices}, а также coords всех патчей.\n",
    "    \"\"\"\n",
    "    H, W, C = image.shape\n",
    "    if model_names is None:\n",
    "        model_names = list(models_dict.keys())\n",
    "    batch_size = config[\"batch_size\"] if config and \"batch_size\" in config else 8\n",
    "\n",
    "    # Для каждого патча храним координаты и patch\n",
    "    patch_coords = []\n",
    "    patches = []\n",
    "    for y in range(0, H - patch_h + 1, stride_h):\n",
    "        for x in range(0, W - patch_w + 1, stride_w):\n",
    "            patch = image[y:y+patch_h, x:x+patch_w]\n",
    "            patches.append(patch)\n",
    "            patch_coords.append((y, x))\n",
    "    patch_tensors = [preprocess(p) for p in patches]\n",
    "    patch_batch = torch.stack(patch_tensors)  # [N, C, H, W]\n",
    "\n",
    "    # Словарь: для каждой модели — список предсказанных классов для каждого патча\n",
    "    results_dict = {}\n",
    "    for model_name in model_names:\n",
    "        torch.cuda.empty_cache()\n",
    "        model = models_dict[model_name]().to(device)\n",
    "        model.eval()\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(f'best_{model_name}.pth', map_location=device))\n",
    "        except Exception as e:\n",
    "            print(f\"[{model_name}] checkpoint not loaded: {e}\")\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(patch_batch), batch_size):\n",
    "                batch = patch_batch[i:i+batch_size].to(device)\n",
    "                logits = model(batch)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                pred_class = probs.argmax(dim=1).cpu().numpy()\n",
    "                preds.append(pred_class)\n",
    "                del batch, logits, probs\n",
    "                torch.cuda.empty_cache()\n",
    "        preds = np.concatenate(preds, axis=0)  # [num_patches]\n",
    "\n",
    "        # Собираем предсказанную \"карту\" классов (кластеризуем патчи обратно в 2D-матрицу)\n",
    "        map_H = (H - patch_h) // stride_h + 1\n",
    "        map_W = (W - patch_w) // stride_w + 1\n",
    "        class_map = preds.reshape(map_H, map_W)\n",
    "        results_dict[model_name] = class_map\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    del patch_batch, patch_tensors, patches\n",
    "    torch.cuda.empty_cache()\n",
    "    return results_dict, patch_coords, (map_H, map_W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def show_classification_map(\n",
    "    image, class_map, patch_h, patch_w, stride_h, stride_w, idx2label=None, model_name=\"Model\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Визуализация исходного изображения и карты предсказанных классов (псевдоцвет).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{model_name}: Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # \"разворачиваем\" карту в исходные координаты для наглядности\n",
    "    H, W = image.shape[:2]\n",
    "    map_H, map_W = class_map.shape\n",
    "    vis_map = np.zeros((H, W), dtype=np.int32)\n",
    "    for i in range(map_H):\n",
    "        for j in range(map_W):\n",
    "            y = i * stride_h\n",
    "            x = j * stride_w\n",
    "            vis_map[y:y+patch_h, x:x+patch_w] = class_map[i, j]\n",
    "    cmap = plt.get_cmap('tab20' if class_map.max() < 20 else 'nipy_spectral')\n",
    "    im = plt.imshow(vis_map, cmap=cmap, vmin=0, vmax=class_map.max())\n",
    "    plt.title(f\"{model_name}: Predicted Classes Map\")\n",
    "    plt.axis('off')\n",
    "    cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    if idx2label:\n",
    "        labels = [idx2label[i] for i in range(class_map.max() + 1)]\n",
    "        cbar.set_ticks(range(len(labels)))\n",
    "        cbar.set_ticklabels(labels)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def save_classification_map_image(\n",
    "    image, class_map, patch_h, patch_w, stride_h, stride_w, idx2label=None,\n",
    "    model_name=\"Model\", save_dir=\"./inference_results\", img_id=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Сохраняет визуализацию карты классов, наложенной на исходное изображение.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    H, W = image.shape[:2]\n",
    "    map_H, map_W = class_map.shape\n",
    "    vis_map = np.zeros((H, W), dtype=np.int32)\n",
    "    for i in range(map_H):\n",
    "        for j in range(map_W):\n",
    "            y = i * stride_h\n",
    "            x = j * stride_w\n",
    "            vis_map[y:y+patch_h, x:x+patch_w] = class_map[i, j]\n",
    "    cmap = plt.get_cmap('tab20' if class_map.max() < 20 else 'nipy_spectral')\n",
    "\n",
    "    # Сохраняем как RGB (цветную карту классов)\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{model_name}: Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    im = plt.imshow(vis_map, cmap=cmap, vmin=0, vmax=class_map.max())\n",
    "    plt.title(f\"{model_name}: Predicted Classes Map\")\n",
    "    plt.axis('off')\n",
    "    cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    if idx2label:\n",
    "        labels = [idx2label[i] for i in range(class_map.max() + 1)]\n",
    "        cbar.set_ticks(range(len(labels)))\n",
    "        cbar.set_ticklabels(labels)\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(save_dir, f\"{model_name}_classmap_{img_id}.png\")\n",
    "    plt.savefig(fname, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "    print(f\"Saved: {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Препроцессинг патчей ---\n",
    "preprocess_albu = A.Compose([\n",
    "    A.Resize(PATCH_H, PATCH_W),  # 224, 224\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "def preprocess_patch(patch):\n",
    "    return preprocess_albu(image=patch)['image']\n",
    "\n",
    "# --- Выбор изображения ---\n",
    "IMG_DIR = Path('./aitex_data/extracted/Defect_images')\n",
    "img_files = sorted(list(IMG_DIR.glob('*.png')))\n",
    "img_path = img_files[0]\n",
    "\n",
    "img = cv2.imread(str(img_path))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# --- Инференс ---\n",
    "result_classmaps, patch_coords, (map_H, map_W) = infer_full_image_classification_with_models(\n",
    "    img,\n",
    "    models_dict=MODELS,\n",
    "    preprocess=preprocess_patch,\n",
    "    patch_h=PATCH_H,\n",
    "    patch_w=PATCH_W,\n",
    "    stride_h=STRIDE_H,\n",
    "    stride_w=STRIDE_W,\n",
    "    device=device,\n",
    "    config=CONFIG\n",
    ")\n",
    "\n",
    "# --- Визуализация ---\n",
    "for model_name, class_map in result_classmaps.items():\n",
    "    show_classification_map(\n",
    "        img, class_map,\n",
    "        patch_h=PATCH_H, patch_w=PATCH_W,\n",
    "        stride_h=STRIDE_H, stride_w=STRIDE_W,\n",
    "        idx2label=train_ds.idx2label,  # или свой словарь {int: str}\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "save_dir = \"./inference_results\"\n",
    "for idx, (model_name, class_map) in enumerate(result_classmaps.items()):\n",
    "    save_classification_map_image(\n",
    "        img, class_map,\n",
    "        patch_h=PATCH_H, patch_w=PATCH_W,\n",
    "        stride_h=STRIDE_H, stride_w=STRIDE_W,\n",
    "        idx2label=train_ds.idx2label,  # или свой словарь\n",
    "        model_name=model_name,\n",
    "        save_dir=save_dir,\n",
    "        img_id=idx\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name, class_map in result_classmaps.items():\n",
    "    uniques, counts = np.unique(class_map, return_counts=True)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for idx, cnt in zip(uniques, counts):\n",
    "        print(f\"  {train_ds.idx2label[idx]}: {cnt} патчей\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
