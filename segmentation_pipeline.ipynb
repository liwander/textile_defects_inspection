{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "requests\n",
    "tqdm>=4.65.0\n",
    "torch>=2.0.0\n",
    "torchvision>=0.14.0\n",
    "opencv-python\n",
    "numpy>=1.23.0\n",
    "pandas>=1.3.0\n",
    "timm>=0.6.13\n",
    "tensorboard>=2.13.0\n",
    "albumentations>=1.3.0\n",
    "scikit-learn>=1.1.0\n",
    "matplotlib>=3.5.0\n",
    "transformers>=4.31.0\n",
    "segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è ---\n",
    "CONFIG = {\n",
    "    'batch_size': 16,\n",
    "    'num_workers': 4,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-3 ,\n",
    "    'weight_decay': 1e-5,\n",
    "    'early_stop_patience': 10,\n",
    "    'dataroot': './aitex_data/extracted',\n",
    "    'log_dir': 'runs/segmentation_experiment',\n",
    "    'resume': False  # –ü–æ—Å—Ç–∞–≤—å—Ç–µ True, —á—Ç–æ–±—ã –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞\n",
    "}\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "MODELS = {\n",
    "    \"swin-unet\": lambda: smp.Unet(\n",
    "        encoder_name=\"tu-swinv2_base_window16_256\",           # –í—ã–±–æ—Ä transformer encoder\n",
    "        encoder_weights=\"imagenet\",      # –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ (–∏–ª–∏ None)\n",
    "        in_channels=3,\n",
    "        classes=1,                       # –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "        activation=None,                 # –ª–æ–≥–∏—Ç—ã\n",
    "    ),\n",
    "    \"segformer_mit_b3\": lambda: smp.Segformer(\n",
    "        encoder_name=\"mit_b3\",           # –í—ã–±–æ—Ä transformer encoder\n",
    "        encoder_weights=\"imagenet\",      # –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ (–∏–ª–∏ None)\n",
    "        in_channels=3,\n",
    "        classes=1,                       # –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "        activation=None,                 # –ª–æ–≥–∏—Ç—ã\n",
    "    ),\n",
    "  \n",
    "    \"unetplusplus_resnet50\": lambda: smp.UnetPlusPlus(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None,\n",
    "    ),\n",
    "    \"deeplabv3plus_resnet101\": lambda: smp.DeepLabV3Plus(\n",
    "        encoder_name=\"resnet101\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice(preds, targets, smooth=1e-7):\n",
    "    preds = preds.float()\n",
    "    targets = targets.float()\n",
    "    intersection = (preds * targets).sum()\n",
    "    union = preds.sum() + targets.sum()\n",
    "    dice = (2 * intersection + smooth) / (union + smooth)\n",
    "    return dice.item()\n",
    "\n",
    "def compute_iou(preds, targets, smooth=1e-7):\n",
    "    preds = preds.float()\n",
    "    targets = targets.float()\n",
    "    intersection = (preds * targets).sum()\n",
    "    union = preds.sum() + targets.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou.item()\n",
    "\n",
    "def compute_accuracy(preds, targets):\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "def compute_precision(preds, targets, eps=1e-7):\n",
    "    tp = ((preds == 1) & (targets == 1)).sum().item()\n",
    "    fp = ((preds == 1) & (targets == 0)).sum().item()\n",
    "    return tp / (tp + fp + eps)\n",
    "\n",
    "def compute_recall(preds, targets, eps=1e-7):\n",
    "    tp = ((preds == 1) & (targets == 1)).sum().item()\n",
    "    fn = ((preds == 0) & (targets == 1)).sum().item()\n",
    "    return tp / (tp + fn + eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits).clamp(self.eps, 1-self.eps)   # ‚Üê –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ\n",
    "        pt = torch.where(targets == 1, probs, 1-probs)\n",
    "        loss = -self.alpha * (1-pt).pow(self.gamma) * pt.log()\n",
    "        return loss.mean()\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        inter = (probs * targets).sum((1,2,3))\n",
    "        union = probs.sum((1,2,3)) + targets.sum((1,2,3))\n",
    "        dice  = (2*inter + self.eps) / (union + self.eps)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "class FDLoss(torch.nn.Module):\n",
    "    \"\"\"L = w_f * Focal + (1-w_f) * Dice\"\"\"\n",
    "    def __init__(self, wf=0.1, gamma=2.0, alpha=0.25):\n",
    "        super().__init__()\n",
    "        self.wf    = wf\n",
    "        self.focal = FocalLoss(gamma=gamma, alpha=alpha)\n",
    "        self.dice  = DiceLoss()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        return self.wf * self.focal(logits, targets) + \\\n",
    "               (1.0 - self.wf) * self.dice(logits, targets)\n",
    "\n",
    "class BCEDiceLoss(torch.nn.Module):\n",
    "    def __init__(self, bce_weight=0.8, dice_weight=0.2):\n",
    "        super().__init__()\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        return self.bce_weight * self.bce(logits, targets) + \\\n",
    "               self.dice_weight * self.dice(logits, targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f301d04-e66c-4c9f-8de5-dbe2914a8008"
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24403371-53b2-4d52-801a-c2c8e70e884b"
   },
   "source": [
    "## download_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5f9c7e7-768c-4a28-a6df-65cfc48fb7d2",
    "outputId": "51bca206-2f9d-4a8c-e2b4-29e6207b0562"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/nexuswho/aitex-fabric-image-database\"\n",
    "output_dir = Path(\"./aitex_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "zip_path = output_dir / \"aitex.zip\"\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞\n",
    "if zip_path.exists():\n",
    "    print(f\"[INFO] –ê—Ä—Ö–∏–≤ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ø–æ –ø—É—Ç–∏: {zip_path}\")\n",
    "else:\n",
    "    print(f\"[INFO] –°–∫–∞—á–∏–≤–∞–µ–º –∞—Ä—Ö–∏–≤ –∏–∑ {url}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n",
    "                f.write(chunk)\n",
    "        print(\"[INFO] –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\")\n",
    "    else:\n",
    "        raise Exception(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: —Å—Ç–∞—Ç—É—Å {response.status_code}\")\n",
    "\n",
    "# –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞\n",
    "extract_dir = output_dir / \"extracted\"\n",
    "if not extract_dir.exists():\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"[INFO] –ê—Ä—Ö–∏–≤ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω –≤ {extract_dir}\")\n",
    "else:\n",
    "    print(f\"[INFO] –ê—Ä—Ö–∏–≤ —É–∂–µ –±—ã–ª —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω –≤ {extract_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQ7TjMBbXK_W"
   },
   "source": [
    "## remove_image_without_masks¬∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3d_pjjlXPlU",
    "outputId": "fb355904-d0a4-4519-b64d-11269c69470a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_images_without_masks(image_dir, mask_dir, image_suffix=\".png\", mask_suffix=\"_mask.png\"):\n",
    "    \"\"\"\n",
    "    –£–¥–∞–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –º–∞—Å–∫–∞.\n",
    "    \"\"\"\n",
    "    removed = 0\n",
    "    for img_name in os.listdir(image_dir):\n",
    "        if not img_name.endswith(image_suffix):\n",
    "            continue\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        mask_name = base_name + mask_suffix\n",
    "        mask_path = os.path.join(mask_dir, mask_name)\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"–£–¥–∞–ª—è–µ—Ç—Å—è {img_path} (–º–∞—Å–∫–∞ {mask_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞)\")\n",
    "            os.remove(img_path)\n",
    "            removed += 1\n",
    "    print(f\"–£–¥–∞–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –º–∞—Å–æ–∫: {removed}\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞:\n",
    "remove_images_without_masks(\n",
    "    image_dir=\"./aitex_data/extracted/Defect_images\",\n",
    "    mask_dir=\"./aitex_data/extracted/Mask_images\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "SRC_MSK_DIR = Path(\"./aitex_data/extracted/Mask_images\")\n",
    "\n",
    "min_pixels = None\n",
    "max_pixels = 0\n",
    "pixels_list = []\n",
    "\n",
    "for mask_path in SRC_MSK_DIR.glob(\"*.png\"):\n",
    "    msk = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if msk is None:\n",
    "        continue\n",
    "    num = int((msk > 0).sum())\n",
    "    if num > 0:\n",
    "        pixels_list.append(num)\n",
    "        if min_pixels is None or num < min_pixels:\n",
    "            min_pixels = num\n",
    "        if num > max_pixels:\n",
    "            max_pixels = num\n",
    "\n",
    "print(f\"–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏–∫—Å–µ–ª–µ–π –¥–µ—Ñ–µ–∫—Ç–∞ –≤ –æ–¥–Ω–æ–π –º–∞—Å–∫–µ: {min_pixels}\")\n",
    "print(f\"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ: {max_pixels}\")\n",
    "print(f\"–ú–µ–¥–∏–∞–Ω–Ω–æ–µ: {np.median(pixels_list)}\")\n",
    "print(f\"–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –ø–æ –≤—Å–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º:\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(pixels_list, bins=30)\n",
    "plt.xlabel(\"–î–µ—Ñ–µ–∫—Ç–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π –Ω–∞ –º–∞—Å–∫–µ\")\n",
    "plt.ylabel(\"–ß–∞—Å—Ç–æ—Ç–∞\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSsXI-e0SWx2"
   },
   "source": [
    "## slice_to_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JeXy3qNSW8E",
    "outputId": "074b13a5-edcd-4632-ea7c-830dc8ba1e02"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- –ú–µ—Ç–∫–∏ –¥–µ—Ñ–µ–∫—Ç–æ–≤ ---\n",
    "DEFECT_LABELS = {\n",
    "    '000': 'No defect',\n",
    "    '002': 'Broken end',\n",
    "    '006': 'Broken yarn',\n",
    "    '010': 'Broken pick',\n",
    "    '016': 'Weft curling',\n",
    "    '019': 'Fuzzyball',\n",
    "    '022': 'Cut selvage',\n",
    "    '023': 'Crease',\n",
    "    '025': 'Warp ball',\n",
    "    '027': 'Knots',\n",
    "    '029': 'Contamination',\n",
    "    '030': 'Nep',\n",
    "    '036': 'Weft crack'\n",
    "}\n",
    "\n",
    "# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Ä–µ–∑–∫–∏ ---\n",
    "SRC_IMG_DIR = Path(\"./aitex_data/extracted/Defect_images\")\n",
    "SRC_MSK_DIR = Path(\"./aitex_data/extracted/Mask_images\")\n",
    "DST_IMG_DIR = Path(\"./aitex_patches/images\")\n",
    "DST_MSK_DIR = Path(\"./aitex_patches/masks\")\n",
    "\n",
    "PATCH_W = PATCH_H = 256\n",
    "STRIDE_W = STRIDE_H = 64\n",
    "# MIN_DEFECT_FRAC = 0.005       # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –¥–µ—Ñ–µ–∫—Ç–∞\n",
    "MIN_DEFECT_PIXELS = 8\n",
    "KEEP_NEG = 0.05\n",
    "\n",
    "DST_IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DST_MSK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "PATCH_AREA = PATCH_W * PATCH_H\n",
    "\n",
    "def has_large_defect(mask, min_size=20):\n",
    "    num_labels, _, stats, _ = cv2.connectedComponentsWithStats((mask > 0).astype(np.uint8))\n",
    "    for i in range(1, num_labels):  # 0 ‚Äî —Ñ–æ–Ω\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for img_path in tqdm(sorted(SRC_IMG_DIR.glob(\"*.png\")), desc=\"Cropping AITEX (grid)\"):\n",
    "    mask_path = SRC_MSK_DIR / img_path.name.replace(\".png\", \"_mask.png\")\n",
    "    img = cv2.imread(str(img_path))\n",
    "    msk = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None or msk is None:\n",
    "        print(f\"‚ùå  –ü—Ä–æ–ø—É—Å–∫ {img_path.name} (—Ñ–∞–π–ª–∞ –Ω–µ—Ç)\")\n",
    "        continue\n",
    "\n",
    "    msk_bin = (msk > 0).astype(np.uint8)\n",
    "    orig_defect_code_str = img_path.stem.split('_')[1]\n",
    "    orig_defect_code = int(orig_defect_code_str)\n",
    "    orig_defect_label = DEFECT_LABELS.get(orig_defect_code_str, \"Unknown\")\n",
    "\n",
    "    # –î–í–ê –¶–ò–ö–õ–ê: –ø–æ y –∏ –ø–æ x\n",
    "    for y in range(0, img.shape[0] - PATCH_H + 1, STRIDE_H):\n",
    "        for x in range(0, img.shape[1] - PATCH_W + 1, STRIDE_W):\n",
    "            img_crop = img[y:y+PATCH_H, x:x+PATCH_W]\n",
    "            msk_crop = msk_bin[y:y+PATCH_H, x:x+PATCH_W]\n",
    "            pos_pix = int(msk_crop.sum())\n",
    "            defect_frac = pos_pix / PATCH_AREA\n",
    "\n",
    "            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä\n",
    "            # is_defective = (defect_frac >= MIN_DEFECT_FRAC) or (pos_pix >= MIN_DEFECT_PIXELS)\n",
    "\n",
    "            is_defective = pos_pix >= MIN_DEFECT_PIXELS\n",
    "\n",
    "            \n",
    "            patch_defect_code = orig_defect_code\n",
    "            patch_defect_label = orig_defect_label\n",
    "\n",
    "            # –ï—Å–ª–∏ –ø–∞—Ç—á \"—á–∏—Å—Ç—ã–π\", –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–∫—É\n",
    "            if not is_defective or not has_large_defect(msk_crop, min_size=20):\n",
    "                if np.random.rand() > KEEP_NEG:\n",
    "                    continue\n",
    "                patch_defect_code = 0\n",
    "                patch_defect_label = DEFECT_LABELS['000']\n",
    "\n",
    "            suffix = f\"x{x:04d}_y{y:04d}\"\n",
    "            fname  = f\"{img_path.stem}_{suffix}.png\"\n",
    "            cv2.imwrite(str(DST_IMG_DIR / fname), img_crop)\n",
    "            cv2.imwrite(str(DST_MSK_DIR / fname), msk_crop * 255)\n",
    "            rows.append((fname, patch_defect_code, patch_defect_label))\n",
    "\n",
    "# --- –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV —Å –º–µ—Ç–∫–∞–º–∏ ---\n",
    "label_path = Path(\"./aitex_patches/patch_labels.csv\")\n",
    "label_df = pd.DataFrame(rows, columns=[\"file\", \"defect_code\", \"defect_label\"])\n",
    "label_df.to_csv(label_path, index=False)\n",
    "print(\"üìù  Saved\", len(rows), \"patch labels ‚Üí\", label_path)\n",
    "print(\"‚úÖ  –ù–∞—Ä–µ–∑–∫–∞ –ø–∞—Ç—á–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./aitex_patches/patch_labels.csv')\n",
    "has_defect = df[df['defect_label'] != 'No defect']\n",
    "no_defect  = df[df['defect_label'] == 'No defect']\n",
    "\n",
    "print(f\"–î–µ—Ñ–µ–∫—Ç–Ω—ã—Ö –ø–∞—Ç—á–µ–π: {len(has_defect)}\")\n",
    "print(f\"–ß–∏—Å—Ç—ã—Ö –ø–∞—Ç—á–µ–π: {len(no_defect)}\")\n",
    "\n",
    "desired_ratio = 1.0  # –Ω–∞–ø—Ä–∏–º–µ—Ä, 1:1\n",
    "n_defect = len(has_defect)\n",
    "n_no_defect = min(int(n_defect * desired_ratio), len(no_defect))\n",
    "\n",
    "no_defect_sampled = no_defect.sample(n=n_no_defect, random_state=42)\n",
    "df_balanced = pd.concat([has_defect, no_defect_sampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "balanced_label_path = './aitex_patches/patch_labels_balanced.csv'\n",
    "df_balanced.to_csv(balanced_label_path, index=False)\n",
    "print(f\"Balanced CSV saved: {balanced_label_path}\")\n",
    "\n",
    "# --- –ù–æ–≤—ã–π –≤—ã–≤–æ–¥ ---\n",
    "summary = df_balanced['defect_label'].value_counts().reset_index()\n",
    "summary.columns = ['defect_label', 'num_patches']\n",
    "summary['percentage'] = (summary['num_patches'] / summary['num_patches'].sum() * 100).round(2)\n",
    "\n",
    "print(\"\\n=== Patch distribution (balanced) ===\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "PATCH_LABEL_PATH = balanced_label_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_patches_with_masks_and_labels(\n",
    "    img_dir,\n",
    "    mask_dir,\n",
    "    csv_path,\n",
    "    min_defect_pixels=MIN_DEFECT_PIXELS,\n",
    "    n_pos=6,\n",
    "    n_neg=6\n",
    "):\n",
    "    \"\"\"\n",
    "    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–∞—Ç—á–∏ —Å –¥–µ—Ñ–µ–∫—Ç–æ–º –∏ –±–µ–∑ –¥–µ—Ñ–µ–∫—Ç–∞:\n",
    "    - –û—Ä–∏–≥–∏–Ω–∞–ª (RGB)\n",
    "    - –ú–∞—Å–∫–∞ (–æ—Ç–¥–µ–ª—å–Ω–æ)\n",
    "    - –ù–∞–ª–æ–∂–µ–Ω–∏–µ –º–∞—Å–∫–∏ (Mask Overlay)\n",
    "    –í –∑–∞–≥–æ–ª–æ–≤–∫–µ ‚Äî —Å—Ç–∞—Ç—É—Å (DEFECT/CLEAN) –∏ –∫–ª–∞—Å—Å –¥–µ—Ñ–µ–∫—Ç–∞.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    pos_samples, neg_samples = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        mask_path = Path(mask_dir) / row['file']\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            continue\n",
    "        defect_pixels = (mask > 0).sum()\n",
    "        info = (row['file'], row['defect_label'])\n",
    "        if defect_pixels >= min_defect_pixels:\n",
    "            pos_samples.append(info)\n",
    "        else:\n",
    "            neg_samples.append(info)\n",
    "\n",
    "    pos_samples = random.sample(pos_samples, min(n_pos, len(pos_samples)))\n",
    "    neg_samples = random.sample(neg_samples, min(n_neg, len(neg_samples)))\n",
    "    all_samples = [(fname, \"DEFECT\", label) for fname, label in pos_samples] + \\\n",
    "                  [(fname, \"CLEAN\", label) for fname, label in neg_samples]\n",
    "\n",
    "    plt.figure(figsize=(len(all_samples) * 4, 10))\n",
    "    for i, (fname, status, defect_label) in enumerate(all_samples):\n",
    "        img = cv2.imread(str(Path(img_dir) / fname))\n",
    "        mask = cv2.imread(str(Path(mask_dir) / fname), cv2.IMREAD_GRAYSCALE)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 1. –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "        plt.subplot(3, len(all_samples), i + 1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(f\"{status}\\n{defect_label}\\n{fname}\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 2. –ú–∞—Å–∫–∞ (–æ—Ç–¥–µ–ª—å–Ω–æ)\n",
    "        plt.subplot(3, len(all_samples), len(all_samples) + i + 1)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.title(\"Mask\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 3. –ù–∞–ª–æ–∂–µ–Ω–∏–µ –º–∞—Å–∫–∏\n",
    "        plt.subplot(3, len(all_samples), 2 * len(all_samples) + i + 1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.imshow(mask, cmap='Reds', alpha=0.5)\n",
    "        plt.title(\"Overlay\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- –ó–∞–ø—É—Å–∫ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ ---\n",
    "visualize_patches_with_masks_and_labels(\n",
    "    img_dir=DST_IMG_DIR,\n",
    "    mask_dir=DST_MSK_DIR,\n",
    "    csv_path=PATCH_LABEL_PATH,\n",
    "    min_defect_pixels=MIN_DEFECT_PIXELS,  # –∫–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ!\n",
    "    n_pos=6,\n",
    "    n_neg=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5603c4bf-2c6b-41e6-a789-5b3b4afb6fb1"
   },
   "source": [
    "## augmenations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ transforms.py (–∏–ª–∏ –ª—é–±–∞—è –≤–∞—à–∞ —è—á–µ–π–∫–∞) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "_IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "_IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "def get_strong_train_transform(image_size=(256, 256)):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(*image_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Affine(scale=(0.9, 1.1),\n",
    "                     translate_percent=0.1,\n",
    "                     rotate=(-25, 25),\n",
    "                     p=0.7),\n",
    "            A.ElasticTransform(alpha=1, sigma=50, p=0.3),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.2),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.HueSaturationValue(p=0.3),\n",
    "            A.GaussNoise(p=0.4),\n",
    "            A.GaussianBlur(p=0.3),\n",
    "\n",
    "            # ‚úì –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∫–ª—é—á–∏ + –∑–∞–¥–∞—ë–º min_* (–∏–Ω–∞—á–µ Albumentations –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ—Ç)\n",
    "            A.CoarseDropout(\n",
    "                max_holes=4, min_holes=1,       # ‚Üê –≤–∞–∂–Ω–æ\n",
    "                max_height=16, min_height=4,\n",
    "                max_width=16,  min_width=4,\n",
    "                fill_value=0, p=0.3\n",
    "            ),\n",
    "\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        additional_targets={\"mask\": \"mask\"},\n",
    "    )\n",
    "\n",
    "def get_weak_train_transform(image_size=(256, 256)):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(*image_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=_IMAGENET_MEAN, std=_IMAGENET_STD),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        additional_targets={\"mask\": \"mask\"},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9564655-5c04-45e3-af7b-c6a48c992e00"
   },
   "source": [
    "## dataset_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class AITEXPatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂:\n",
    "        (image_tensor, mask_tensor, defect_code:int, defect_label:str)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_dir,                       # ./aitex_patches/images\n",
    "        msk_dir,                       # ./aitex_patches/masks\n",
    "        file_list,                     # —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤ *.png\n",
    "        label_map,                     # {fname: (code:int, label:str)}\n",
    "        strong_transform,              # albumentations Compose (defect)\n",
    "        weak_transform,                # albumentations Compose (clean)\n",
    "        *,\n",
    "        enable_copy_paste: bool = False,\n",
    "        copy_paste_classwise: bool = False,\n",
    "        class_copy_paste_probs: dict[int, float] | None = None,\n",
    "        copy_paste_prob: float = 0.2,          # ‚Üê –µ–¥–∏–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å CP\n",
    "        random_state: int = 42,\n",
    "    ):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.msk_dir = Path(msk_dir)\n",
    "        self.file_list = file_list\n",
    "        self.label_map = label_map\n",
    "        self.strong_transform = strong_transform\n",
    "        self.weak_transform = weak_transform\n",
    "\n",
    "        self.enable_copy_paste = enable_copy_paste\n",
    "        self.copy_paste_classwise = copy_paste_classwise\n",
    "        self.class_copy_paste_probs = class_copy_paste_probs or {}\n",
    "        self.copy_paste_prob = copy_paste_prob\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "\n",
    "        # –¥–ª—è class-aware CP\n",
    "        self.class_to_files: dict[int, list[str]] = {}\n",
    "        for f in self.file_list:\n",
    "            code = self.label_map[f][0]\n",
    "            if code != 0:\n",
    "                self.class_to_files.setdefault(code, []).append(f)\n",
    "\n",
    "        self.defect_files = [f for f in self.file_list if self.label_map[f][0] != 0]\n",
    "\n",
    "    # --------------------------------------------------------------------- len --\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.file_list)\n",
    "\n",
    "    # -------------------------------------------------------------------- getitem\n",
    "    def __getitem__(self, idx: int):\n",
    "        fname = self.file_list[idx]\n",
    "\n",
    "        # ------- –∑–∞–≥—Ä—É–∑–∫–∞ -------------------------------------------------------\n",
    "        img = cv2.cvtColor(cv2.imread(str(self.img_dir / fname)), cv2.COLOR_BGR2RGB)\n",
    "        msk = cv2.imread(str(self.msk_dir / fname), cv2.IMREAD_GRAYSCALE)\n",
    "        msk = (msk > 0).astype(np.uint8)\n",
    "\n",
    "        defect_code, defect_label = self.label_map[fname]\n",
    "\n",
    "        # ------- probabilistic Copy-Paste –¥–ª—è —á–∏—Å—Ç—ã—Ö ---------------------------\n",
    "        if (\n",
    "            self.enable_copy_paste\n",
    "            and defect_code == 0\n",
    "            and len(self.defect_files) > 0\n",
    "            and self.rng.rand() < self.copy_paste_prob          # !!! –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å\n",
    "        ):\n",
    "            # –≤—ã–±–æ—Ä ¬´–¥–æ–Ω–æ—Ä–∞¬ª\n",
    "            if self.copy_paste_classwise and self.class_copy_paste_probs:\n",
    "                codes, probs = zip(*self.class_copy_paste_probs.items())\n",
    "                sel_code = self.rng.choice(codes, p=probs)\n",
    "                pool = self.class_to_files.get(sel_code, self.defect_files)\n",
    "            else:\n",
    "                pool = self.defect_files\n",
    "\n",
    "            paste_fname = self.rng.choice(pool)\n",
    "\n",
    "            # –≤—Å—Ç–∞–≤–∫–∞ –¥–µ—Ñ–µ–∫—Ç–∞\n",
    "            paste_img = cv2.cvtColor(cv2.imread(str(self.img_dir / paste_fname)), cv2.COLOR_BGR2RGB)\n",
    "            paste_msk = cv2.imread(str(self.msk_dir / paste_fname), cv2.IMREAD_GRAYSCALE) > 0\n",
    "\n",
    "            img[paste_msk] = paste_img[paste_msk]\n",
    "            msk[paste_msk] = 1\n",
    "            defect_code, defect_label = self.label_map[paste_fname]\n",
    "\n",
    "        # ------- –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ----------------------------------------------------\n",
    "        if defect_code != 0:\n",
    "            aug = self.strong_transform(image=img, mask=msk)\n",
    "        else:\n",
    "            aug = self.weak_transform(image=img, mask=msk)\n",
    "\n",
    "        img_t, msk_t = aug[\"image\"], aug[\"mask\"]\n",
    "        return img_t, msk_t, defect_code, defect_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset creation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ prepare_patch_datasets (–æ–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_class_copy_paste_probs(train_files, label_map):\n",
    "    cnt = Counter(label_map[f][0] for f in train_files if label_map[f][0] != 0)\n",
    "    med = int(np.median(list(cnt.values()))) or 1\n",
    "    deficit = {c: med - n for c, n in cnt.items() if n < med}\n",
    "    total = sum(deficit.values())\n",
    "    probs = {c: d / total for c, d in deficit.items()} if total else {}\n",
    "    return probs, med, cnt\n",
    "\n",
    "def prepare_patch_datasets(\n",
    "    patch_root          = \"./aitex_patches\",\n",
    "    patch_label_path    = \"./aitex_patches/patch_labels_balanced.csv\",\n",
    "    *,\n",
    "    test_size           = 0.05,\n",
    "    val_size            = 0.10,\n",
    "    random_state        = 42,\n",
    "    image_size          = (256, 256),          # (PATCH_H, PATCH_W)\n",
    "    copy_paste_prob     = 0.8,\n",
    "    strong_tr           = None,\n",
    "    weak_tr             = None,\n",
    "):\n",
    "    img_dir = Path(patch_root) / \"images\"\n",
    "    msk_dir = Path(patch_root) / \"masks\"\n",
    "\n",
    "    df = pd.read_csv(patch_label_path)\n",
    "    label_map = {r.file: (int(r.defect_code), r.defect_label) for _, r in df.iterrows()}\n",
    "\n",
    "    files = sorted(label_map)\n",
    "    strat = [1 if label_map[f][0] else 0 for f in files]\n",
    "    train_val, test = train_test_split(files, test_size=test_size, stratify=strat,\n",
    "                                       random_state=random_state, shuffle=True)\n",
    "    train, val = train_test_split(train_val, test_size=val_size/(1-test_size),\n",
    "                                  random_state=random_state, shuffle=True)\n",
    "\n",
    "    # --- –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ----------------------------------------------------------\n",
    "    if strong_tr is None:\n",
    "        strong_tr = get_strong_train_transform(image_size)\n",
    "    if weak_tr is None:\n",
    "        weak_tr = get_weak_train_transform(image_size)\n",
    "\n",
    "    # --- class-aware Copy-Paste probs -----------------------------------------\n",
    "    cp_probs, median, counts = get_class_copy_paste_probs(train, label_map)\n",
    "    print(f\"Copy-Paste up to median={median}.  Counts: {dict(counts)}\")\n",
    "\n",
    "    train_ds = AITEXPatchDataset(\n",
    "        img_dir, msk_dir, train, label_map,\n",
    "        strong_transform=strong_tr,\n",
    "        weak_transform=weak_tr,\n",
    "        enable_copy_paste=True,\n",
    "        copy_paste_classwise=True,\n",
    "        class_copy_paste_probs=cp_probs,\n",
    "        copy_paste_prob=copy_paste_prob,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    val_ds = AITEXPatchDataset(img_dir, msk_dir, val, label_map,\n",
    "                               strong_transform=weak_tr, weak_transform=weak_tr,\n",
    "                               enable_copy_paste=False)\n",
    "    test_ds = AITEXPatchDataset(img_dir, msk_dir, test, label_map,\n",
    "                                strong_transform=weak_tr, weak_transform=weak_tr,\n",
    "                                enable_copy_paste=False)\n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader creation helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataloaders(train_ds, val_ds, test_ds, batch_size=32, num_workers=2, pin_memory=True):\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory, drop_last=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = prepare_patch_datasets(\n",
    "    patch_label_path=PATCH_LABEL_PATH,\n",
    "    image_size=(PATCH_H, PATCH_W)\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    train_ds, val_ds, test_ds,\n",
    "    batch_size=CONFIG['batch_size'], num_workers=CONFIG['num_workers'], pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_ds)}\")\n",
    "print(f\"Validation samples: {len(val_ds)}\")\n",
    "print(f\"Test samples: {len(test_ds)}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def print_class_distribution_from_dataset(dataset, label_names=None, title=\"Train set\"):\n",
    "    \"\"\"\n",
    "    –í—ã–≤–æ–¥–∏—Ç —Ç–∞–±–ª–∏—Ü—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—Ç—á–µ–π –ø–æ –∫–ª–∞—Å—Å–∞–º –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞.\n",
    "    - dataset: —ç–∫–∑–µ–º–ø–ª—è—Ä Dataset (–Ω–∞–ø—Ä–∏–º–µ—Ä, AITEXPatchDataset), –∫–æ—Ç–æ—Ä—ã–π –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (img, mask, code, label)\n",
    "    - label_names: dict –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫—Ä–∞—Å–∏–≤—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, DEFECT_LABELS)\n",
    "    - title: –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –≤—ã–≤–æ–¥–∞\n",
    "    \"\"\"\n",
    "    codes = []\n",
    "    labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        try:\n",
    "            # –°–∞–º—ã–π —á–∞—Å—Ç—ã–π —Å–ª—É—á–∞–π (img, mask, code, label)\n",
    "            _, _, code, label = dataset[i]\n",
    "        except Exception:\n",
    "            # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –¥–ª—è (img, mask, code)\n",
    "            _, _, code = dataset[i]\n",
    "            label = str(code)\n",
    "        codes.append(code)\n",
    "        labels.append(label)\n",
    "\n",
    "    df = pd.DataFrame({'class_code': codes, 'class_label': labels})\n",
    "    summary = df.value_counts(['class_code', 'class_label']).reset_index(name=\"num_patches\")\n",
    "    summary['percentage'] = (summary['num_patches'] / summary['num_patches'].sum() * 100).round(2)\n",
    "    if label_names:\n",
    "        summary['class_label'] = summary['class_code'].map(label_names).fillna(summary['class_label'])\n",
    "\n",
    "    print(f\"\\n=== Patch distribution in {title} ===\")\n",
    "    print(summary.sort_values(\"num_patches\", ascending=False).to_string(index=False))\n",
    "\n",
    "print_class_distribution_from_dataset(train_ds, label_names=DEFECT_LABELS, title=\"Train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:13:36.398507Z",
     "iopub.status.busy": "2025-05-17T08:13:36.397903Z",
     "iopub.status.idle": "2025-05-17T08:13:36.402238Z",
     "shell.execute_reply": "2025-05-17T08:13:36.401567Z",
     "shell.execute_reply.started": "2025-05-17T08:13:36.398482Z"
    }
   },
   "source": [
    "## visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def visualize_dataset_grid(dataset, num_samples=6):\n",
    "    \"\"\"\n",
    "    –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ ‚Äî —Ä–∞–∑–Ω—ã–µ –ø–∞—Ç—á–∏, –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ:\n",
    "    1. –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (RGB)\n",
    "    2. –ú–∞—Å–∫–∞ (–æ—Ç–¥–µ–ª—å–Ω–æ)\n",
    "    3. Overlay (–Ω–∞–ª–æ–∂–µ–Ω–∏–µ –º–∞—Å–∫–∏)\n",
    "    –í –∑–∞–≥–æ–ª–æ–≤–∫–µ ‚Äî –∫–ª–∞—Å—Å –∏ –∫–æ–¥ –¥–µ—Ñ–µ–∫—Ç–∞.\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    plt.figure(figsize=(num_samples * 4, 10))\n",
    "\n",
    "    for col, idx in enumerate(indices):\n",
    "        sample = dataset[idx]\n",
    "        if len(sample) == 4:\n",
    "            image, mask, code, label_str = sample\n",
    "            title = f\"{label_str} (code {code})\"\n",
    "        else:\n",
    "            image, mask, code = sample\n",
    "            title = f\"Class {code}\"\n",
    "\n",
    "        rgb = image[:3].permute(1, 2, 0).cpu().numpy()\n",
    "        rgb = (rgb * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)\n",
    "        mask_np = mask.cpu().numpy()\n",
    "\n",
    "        # 1. –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–≤–µ—Ä—Ö–Ω–∏–π —Ä—è–¥)\n",
    "        plt.subplot(3, num_samples, 1 + col)\n",
    "        plt.imshow(rgb)\n",
    "        plt.title(title, fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # 2. –ú–∞—Å–∫–∞ (—Å—Ä–µ–¥–Ω–∏–π —Ä—è–¥)\n",
    "        plt.subplot(3, num_samples, 1 + num_samples + col)\n",
    "        plt.imshow(mask_np, cmap=\"gray\")\n",
    "        plt.title(\"Mask\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # 3. Overlay (–Ω–∏–∂–Ω–∏–π —Ä—è–¥)\n",
    "        plt.subplot(3, num_samples, 1 + 2 * num_samples + col)\n",
    "        plt.imshow(rgb)\n",
    "        plt.imshow(mask_np, cmap='Reds', alpha=0.5)\n",
    "        plt.title(\"Overlay\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_dataset_grid(test_ds, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d1ff18c-c131-45de-9398-aede203360ae"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3255ae5-59eb-4535-8ef5-ac60786a3d78"
   },
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf07f1c4-b824-4326-83d7-182705364d64"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "753ae338-0818-4155-a3a1-0f41f531c633"
   },
   "source": [
    "#### train_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbe9d1a7-7977-4887-9cdb-49631ed48270"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, loss_fn, scaler, device, epoch, model_name, log_interval=10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # –°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –ø–æ –±–∞—Ç—á–∞–º\n",
    "    dices, ious, accs, precs, recs = [], [], [], [], []\n",
    "\n",
    "    for step, (images, masks, _, _) in enumerate(tqdm(train_loader, desc=f\"Train {epoch}\")):\n",
    "        images = images.to(device)\n",
    "        masks  = masks.unsqueeze(1).float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(enabled=(device.type == 'cuda')):\n",
    "            outputs = model(images)\n",
    "            loss   = loss_fn(outputs, masks)\n",
    "\n",
    "        if device.type == 'cuda':\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –±–∞—Ç—á—É\n",
    "        with torch.no_grad():\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).float()\n",
    "            dices.append(compute_dice(preds, masks))\n",
    "            ious.append(compute_iou(preds, masks))\n",
    "            accs.append(compute_accuracy(preds, masks))\n",
    "            precs.append(compute_precision(preds, masks))\n",
    "            recs.append(compute_recall(preds, masks))\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    metrics = {\n",
    "        'loss': epoch_loss,\n",
    "        'dice': np.mean(dices),\n",
    "        'iou': np.mean(ious),\n",
    "        'accuracy': np.mean(accs),\n",
    "        'precision': np.mean(precs),\n",
    "        'recall': np.mean(recs),\n",
    "    }\n",
    "    print(f\"[{model_name}] Train epoch {epoch}: {metrics}\")\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d138719-faf4-4542-9e15-d2a65f9ee065"
   },
   "source": [
    "#### validate_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4ea0489-92c9-468b-804a-fb298be2ac67"
   },
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, device, epoch, model_name, threshold=0.5):\n",
    "    model.eval()\n",
    "    dices, ious, accs, precs, recs = [], [], [], [], []\n",
    "    running_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (images, masks, _, _) in enumerate(tqdm(val_loader, desc=f\"Val  {epoch}\")):\n",
    "            images = images.to(device)\n",
    "            masks  = masks.unsqueeze(1).float().to(device)\n",
    "            if masks.sum().item() == 0:\n",
    "                continue\n",
    "            outputs = model(images)\n",
    "            probs   = torch.sigmoid(outputs)\n",
    "            preds   = (probs > threshold).float()\n",
    "            # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "            dices.append(compute_dice(preds, masks))\n",
    "            ious.append(compute_iou(preds, masks))\n",
    "            accs.append(compute_accuracy(preds, masks))\n",
    "            precs.append(compute_precision(preds, masks))\n",
    "            recs.append(compute_recall(preds, masks))\n",
    "            running_loss += nn.BCEWithLogitsLoss()(outputs, masks).item()\n",
    "            batches += 1\n",
    "\n",
    "    metrics = {\n",
    "        'loss': running_loss / batches if batches > 0 else 0.0,\n",
    "        'dice': np.mean(dices) if dices else 0.0,\n",
    "        'iou': np.mean(ious) if ious else 0.0,\n",
    "        'accuracy': np.mean(accs) if accs else 0.0,\n",
    "        'precision': np.mean(precs) if precs else 0.0,\n",
    "        'recall': np.mean(recs) if recs else 0.0,\n",
    "    }\n",
    "    print(f\"[{model_name}] Val epoch {epoch}: {metrics}\")\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce566e89-fcb2-4fc9-b633-7f40426ae8a0"
   },
   "source": [
    "### train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf9f600f-462d-4d7f-9edb-9dc8f1f6bb20"
   },
   "outputs": [],
   "source": [
    "def train_loop(\n",
    "    model, optimizer, scheduler, train_loader, val_loader,\n",
    "    loss_fn, device, scaler,\n",
    "    num_epochs=50, early_stop_patience=5, model_name='model'\n",
    "):\n",
    "    best_dice = 0.0\n",
    "    counter   = 0\n",
    "    train_history, val_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch(model, train_loader, optimizer, loss_fn, scaler, device, epoch, model_name)\n",
    "        val_metrics   = validate_epoch(model, val_loader, device, epoch, model_name)\n",
    "\n",
    "        scheduler.step(val_metrics['dice'])\n",
    "\n",
    "        train_history.append(train_metrics)\n",
    "        val_history.append(val_metrics)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_metrics['dice'] > best_dice:\n",
    "            best_dice = val_metrics['dice']\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_{model_name}.pth\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= early_stop_patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Dice={train_metrics['dice']:.4f}  Val Dice={val_metrics['dice']:.4f}\")\n",
    "\n",
    "    print(f\"Best Val Dice: {best_dice:.4f}\")\n",
    "    return train_history, val_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(train_history, val_history, model_name, save_path=None):\n",
    "    epochs = np.arange(1, len(train_history) + 1)\n",
    "    keys = ['loss', 'dice', 'iou', 'accuracy', 'precision', 'recall']\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    for idx, key in enumerate(keys, 1):\n",
    "        plt.subplot(2, 3, idx)\n",
    "        train_vals = [m[key] for m in train_history]\n",
    "        val_vals = [m[key] for m in val_history]\n",
    "        plt.plot(epochs, train_vals, label=f\"Train {key}\")\n",
    "        plt.plot(epochs, val_vals, label=f\"Val {key}\")\n",
    "        plt.title(f\"{model_name}: {key}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0014b2c-1b67-4a7f-aa97-281f74a127cf"
   },
   "source": [
    "## train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ae365e2-c328-4044-8043-7e795ff63d0d"
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "def train_single_model(model_name, model_fn, train_loader, val_loader, config):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # --- Model & Optim ----\n",
    "    model = model_fn().to(device)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3\n",
    "    )\n",
    "\n",
    "    # --- Losses ---\n",
    "    # loss_fn = FDLoss(wf=0.1, gamma=2.0, alpha=0.25).to(device)\n",
    "    # loss_fn = 0.8 * torch.nn.BCEWithLogitsLoss()+ 0.2 * DiceLoss()\n",
    "    # loss_fn = loss_fn.to(device)\n",
    "    loss_fn = BCEDiceLoss(bce_weight=0.8, dice_weight=0.2).to(device)\n",
    "\n",
    "    \n",
    "    # --- AMP scaler ---\n",
    "    scaler = GradScaler() if device.type == 'cuda' else None\n",
    "\n",
    "    # --- TensorBoard ---\n",
    "    writer = SummaryWriter(log_dir=os.path.join(config['log_dir'], model_name))\n",
    "\n",
    "    # --- Resume option ---\n",
    "    checkpoint_path = f\"best_{model_name}.pth\"\n",
    "    if config.get('resume') and os.path.exists(checkpoint_path):\n",
    "        print(f\"Resuming {model_name} from checkpoint‚Ä¶\")\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "\n",
    "    # --- Train ---\n",
    "    train_hist, val_hist = train_loop(\n",
    "        model, optimizer, scheduler, train_loader, val_loader,\n",
    "        loss_fn, device, scaler,\n",
    "        num_epochs=config['num_epochs'],\n",
    "        early_stop_patience=config['early_stop_patience'],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return train_hist, val_hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T08:31:34.969449Z",
     "iopub.status.busy": "2025-05-17T08:31:34.968855Z",
     "iopub.status.idle": "2025-05-17T08:31:34.972959Z",
     "shell.execute_reply": "2025-05-17T08:31:34.972253Z",
     "shell.execute_reply.started": "2025-05-17T08:31:34.969421Z"
    }
   },
   "source": [
    "## run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "def train_all_models(models_dict, train_loader, val_loader, config):\n",
    "    for name, model_fn in models_dict.items():\n",
    "        print(f\"==== Training model: {name} ====\")\n",
    "\n",
    "        # --- –û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ ---\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        train_hist, val_hist = train_single_model(name, model_fn, train_loader, val_loader, config)    \n",
    "        plot_metrics(train_hist, val_hist, model_name=name, save_path=f\"metrics_{name}.png\")\n",
    "        \n",
    "        # --- –û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏!) ---\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "train_all_models(MODELS, train_loader, val_loader, CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e842448e-1511-420a-80ae-604b9906ee7e"
   },
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "613d4e65-8746-43cf-84b5-c2b1500b33f1"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69248cf9-4a14-42ac-a7a3-1078ee5412e4"
   },
   "source": [
    "### tta_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99356348-3504-45cf-a379-fb48203fed90"
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- –§—É–Ω–∫—Ü–∏—è TTA –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ---\n",
    "def tta_predict(model, images):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø—Ä–æ—Å—Ç—É—é –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—É—é TTA: –æ—Ä–∏–≥–∏–Ω–∞–ª + –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        orig = model(images)\n",
    "        flip = model(torch.flip(images, dims=[3]))  # flip horizontally\n",
    "        flip = torch.flip(flip, dims=[3])\n",
    "        return (orig + flip) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96c786e1-1cfa-4043-88f9-f4a5693ade51"
   },
   "source": [
    "### visualize_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fb48f84b-6b6d-42b3-ade3-422749fe74e7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def visualize_predictions_tta_with_label(\n",
    "    model,\n",
    "    dataloader,\n",
    "    device,\n",
    "    num_samples=10,\n",
    "    imagenet_norm=True,\n",
    "    model_title=None  # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä ‚Äî –∏–º—è/–Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "):\n",
    "    \"\"\"\n",
    "    –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ: —Ä–∞–∑–Ω—ã–µ –ø–∞—Ç—á–∏ (num_samples), –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ:\n",
    "    1. RGB\n",
    "    2. Ground Truth\n",
    "    3. Prediction (TTA)\n",
    "    –í –∑–∞–≥–æ–ª–æ–≤–∫–µ –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ ‚Äî –∫–æ–¥ –∏ —Å—Ç—Ä–æ–∫–∞ –∫–ª–∞—Å—Å–∞, –µ—Å–ª–∏ –µ—Å—Ç—å.\n",
    "    model_title ‚Äî –æ–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –≤—Å–µ–π —Ñ–∏–≥—É—Ä—ã (–∏–º—è –º–æ–¥–µ–ª–∏)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "\n",
    "    images_list = []\n",
    "    true_masks_list = []\n",
    "    pred_masks_list = []\n",
    "    titles = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images, masks, *meta = batch\n",
    "            images = images.to(device)\n",
    "            masks  = masks.unsqueeze(1).float().to(device)\n",
    "\n",
    "            outputs = tta_predict(model, images)\n",
    "            probs   = torch.sigmoid(outputs)\n",
    "            preds   = (probs > 0.5).float()\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            label_codes = meta[0] if len(meta) > 0 else [None] * batch_size\n",
    "            label_strs  = meta[1] if len(meta) > 1 else [None] * batch_size\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                if shown >= num_samples:\n",
    "                    break\n",
    "\n",
    "                img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "                if imagenet_norm:\n",
    "                    img = (img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0,1)\n",
    "                true_mask = masks[i].cpu().squeeze().numpy()\n",
    "                pred_mask = preds[i].cpu().squeeze().numpy()\n",
    "\n",
    "                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∫–æ–¥–æ–º –∏ —Å—Ç—Ä–æ–∫–æ–π –∫–ª–∞—Å—Å–∞\n",
    "                label_code = label_codes[i] if label_codes is not None else None\n",
    "                label_str = label_strs[i] if label_strs is not None else None\n",
    "\n",
    "                if label_str is not None and label_code is not None:\n",
    "                    title = f\"Code: {label_code}, {label_str}\"\n",
    "                elif label_code is not None:\n",
    "                    title = f\"Code: {label_code}\"\n",
    "                elif label_str is not None:\n",
    "                    title = f\"{label_str}\"\n",
    "                else:\n",
    "                    title = \"Image\"\n",
    "\n",
    "                images_list.append(img)\n",
    "                true_masks_list.append(true_mask)\n",
    "                pred_masks_list.append(pred_mask)\n",
    "                titles.append(title)\n",
    "\n",
    "                shown += 1\n",
    "            if shown >= num_samples:\n",
    "                break\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ ‚Äî –ø—Ä–∏–º–µ—Ä—ã, –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ ‚Äî Image, GT, Prediction\n",
    "    fig = plt.figure(figsize=(num_samples * 3, 10))\n",
    "    if model_title is not None:\n",
    "        plt.suptitle(model_title, fontsize=18, y=1.02)\n",
    "    for col in range(shown):\n",
    "        # 1. Image\n",
    "        plt.subplot(3, num_samples, col + 1)\n",
    "        plt.imshow(images_list[col])\n",
    "        plt.title(titles[col], fontsize=9)\n",
    "        plt.axis(\"off\")\n",
    "        # 2. GT\n",
    "        plt.subplot(3, num_samples, num_samples + col + 1)\n",
    "        plt.imshow(true_masks_list[col], cmap=\"gray\")\n",
    "        if col == 0:\n",
    "            plt.ylabel(\"GT Mask\", fontsize=12)\n",
    "        plt.axis(\"off\")\n",
    "        # 3. Prediction\n",
    "        plt.subplot(3, num_samples, 2 * num_samples + col + 1)\n",
    "        plt.imshow(pred_masks_list[col], cmap=\"gray\")\n",
    "        if col == 0:\n",
    "            plt.ylabel(\"Prediction\", fontsize=12)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "model_names = list(MODELS.keys())\n",
    "\n",
    "for model_name in model_names:\n",
    "    checkpoint_path = f'best_{model_name}.pth'\n",
    "    print(f\"\\n--- Model: {model_name} ---\")\n",
    "    try:\n",
    "        test_model = MODELS[model_name]().to(device)\n",
    "        test_model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        test_model.eval()\n",
    "        \n",
    "        visualize_predictions_tta_with_label(\n",
    "            test_model,\n",
    "            dataloader=test_loader,\n",
    "            device=device,\n",
    "            num_samples=5,\n",
    "            model_title=f\"Model: {model_name}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not evaluate {model_name}: {e}\")\n",
    "    finally:\n",
    "        # === –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ ===\n",
    "        del test_model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb943ece-2f41-4c50-834d-9a1edf782ca1"
   },
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. –ù–∞–π–¥—ë–º –ø–∞—Ç—á —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø–ª–æ—â–∞–¥—å—é –¥–µ—Ñ–µ–∫—Ç–∞\n",
    "max_defect_idx = None\n",
    "max_defect_mean = 0\n",
    "for i in range(len(train_ds)):\n",
    "    img, mask, code, label = train_ds[i]\n",
    "    m = mask.float().mean().item()\n",
    "    if m > max_defect_mean:\n",
    "        max_defect_mean = m\n",
    "        max_defect_idx = i\n",
    "\n",
    "print(f\"Max defect mean: {max_defect_mean:.4f} at index {max_defect_idx}\")\n",
    "\n",
    "# 2. –î–µ–ª–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç —Å 8 –∫–æ–ø–∏—è–º–∏ –æ–¥–Ω–æ–≥–æ –ø–∞—Ç—á–∞\n",
    "img, mask, *_ = train_ds[max_defect_idx]\n",
    "N = 8\n",
    "single_ds = [(img, mask)] * N\n",
    "single_loader = DataLoader(single_ds, batch_size=N, shuffle=True)\n",
    "\n",
    "# 3. –ü—Ä–æ–≥–æ–Ω–∏–º sanity check –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "for model_name, model_fn in MODELS.items():\n",
    "    print(f\"\\n==== Sanity check: {model_name} ====\")\n",
    "    # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    model = model_fn().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    loss_fn = FDLoss(wf=0.1, gamma=2.0, alpha=0.25)  # –∏–ª–∏ —Ç–≤–æ–π –æ—Å–Ω–æ–≤–Ω–æ–π loss\n",
    "\n",
    "    # –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –ø–∞—Ç—á–µ\n",
    "    for epoch in range(20):\n",
    "        model.train()\n",
    "        for img_batch, mask_batch in single_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            mask_batch = mask_batch.unsqueeze(1).float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(img_batch)\n",
    "            loss = loss_fn(out, mask_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = torch.sigmoid(model(img_batch)).cpu().numpy()\n",
    "            mask_np = mask_batch.cpu().numpy()\n",
    "            print(\"GT mean:\", mask_np.mean(), \"Pred mean:\", pred.mean())\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –ø–∞—Ç—á–∞\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.suptitle(f\"Sanity Check: {model_name}\")\n",
    "    plt.subplot(1, 3, 1); plt.imshow(img[:3].permute(1,2,0).cpu().numpy()); plt.title(\"Image\"); plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2); plt.imshow(mask.squeeze().cpu().numpy(), cmap='gray'); plt.title(\"Mask\"); plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3); plt.imshow(pred[0].squeeze(), cmap='gray'); plt.title(\"Prediction\"); plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. –ù–∞–π—Ç–∏ —á–∏—Å—Ç—ã–π –ø–∞—Ç—á –≤ train_ds (–∫–æ–¥ == 0 –∏ –º–∞—Å–∫–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç–∞—è)\n",
    "clean_idx = None\n",
    "for i in range(len(train_ds)):\n",
    "    img, mask, code, label = train_ds[i]\n",
    "    if code == 0 and mask.float().mean().item() == 0.0:\n",
    "        clean_idx = i\n",
    "        break\n",
    "\n",
    "if clean_idx is None:\n",
    "    raise ValueError(\"–ß–∏—Å—Ç—ã–π –ø–∞—Ç—á –Ω–µ –Ω–∞–π–¥–µ–Ω!\")\n",
    "print(f\"–ß–∏—Å—Ç—ã–π –ø–∞—Ç—á –Ω–∞–π–¥–µ–Ω: index {clean_idx}\")\n",
    "\n",
    "# 2. –î–µ–ª–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç —Å 8 –∫–æ–ø–∏—è–º–∏ –æ–¥–Ω–æ–≥–æ –ø–∞—Ç—á–∞ (–¥–ª—è BatchNorm sanity)\n",
    "img, mask, *_ = train_ds[clean_idx]\n",
    "N = 8\n",
    "single_clean_ds = [(img, mask)] * N\n",
    "single_clean_loader = DataLoader(single_clean_ds, batch_size=N, shuffle=True)\n",
    "\n",
    "# 3. –ü—Ä–æ–≥–æ–Ω–∏–º sanity check –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π\n",
    "for model_name, model_fn in MODELS.items():\n",
    "    print(f\"\\n==== Sanity check on CLEAN: {model_name} ====\")\n",
    "    # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    model = model_fn().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    loss_fn = FDLoss(wf=0.1, gamma=2.0, alpha=0.25)  # –∏–ª–∏ —Ç–≤–æ–π –æ—Å–Ω–æ–≤–Ω–æ–π loss\n",
    "\n",
    "    # –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –ø–∞—Ç—á–µ\n",
    "    for epoch in range(10):  # –æ–±—ã—á–Ω–æ 10 —ç–ø–æ—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ\n",
    "        model.train()\n",
    "        for img_batch, mask_batch in single_clean_loader:\n",
    "            img_batch = img_batch.to(device)\n",
    "            mask_batch = mask_batch.unsqueeze(1).float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(img_batch)\n",
    "            loss = loss_fn(out, mask_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = torch.sigmoid(model(img_batch)).cpu().numpy()\n",
    "            mask_np = mask_batch.cpu().numpy()\n",
    "            print(\"GT mean:\", mask_np.mean(), \"Pred mean:\", pred.mean())\n",
    "\n",
    "    # 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –ø–∞—Ç—á–∞ (–ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –±–∞—Ç—á–∞)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.suptitle(f\"Sanity Check (CLEAN): {model_name}\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img[:3].permute(1, 2, 0).cpu().numpy())\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask.squeeze().cpu().numpy(), cmap='gray')\n",
    "    plt.title(\"Mask\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred[0].squeeze(), cmap='gray')\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41909dd6-9ae4-4a24-80b3-bac29015e091"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def infer_full_image_with_models(\n",
    "    image,\n",
    "    models_dict,\n",
    "    preprocess,\n",
    "    patch_h=256,\n",
    "    patch_w=256,\n",
    "    stride_h=64,\n",
    "    stride_w=64,\n",
    "    device='cuda',\n",
    "    threshold=0.5,\n",
    "    model_names=None,\n",
    "    config=None\n",
    "):\n",
    "    H, W, C = image.shape\n",
    "    if model_names is None:\n",
    "        model_names = list(models_dict.keys())\n",
    "    batch_size = config[\"batch_size\"] if config and \"batch_size\" in config else 8\n",
    "\n",
    "    masks_dict = {name: np.zeros((H, W), dtype=np.float32) for name in model_names}\n",
    "    patch_coords = []\n",
    "    patches = []\n",
    "    for y in range(0, H - patch_h + 1, stride_h):\n",
    "        for x in range(0, W - patch_w + 1, stride_w):\n",
    "            patch = image[y:y+patch_h, x:x+patch_w]\n",
    "            patches.append(patch)\n",
    "            patch_coords.append((y, x))\n",
    "    patch_tensors = [preprocess(p) for p in patches]\n",
    "    patch_batch = torch.stack(patch_tensors)  # [N, C, H, W]\n",
    "\n",
    "    for model_name in model_names:\n",
    "        torch.cuda.empty_cache()\n",
    "        model = models_dict[model_name]().to(device)\n",
    "        model.eval()\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(f'best_{model_name}.pth', map_location=device))\n",
    "        except Exception as e:\n",
    "            print(f\"[{model_name}] checkpoint not loaded: {e}\")\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(patch_batch), batch_size):\n",
    "                batch = patch_batch[i:i+batch_size].to(device)\n",
    "                out = model(batch)\n",
    "                prob = torch.sigmoid(out)\n",
    "                preds.append(prob.cpu().squeeze().numpy())\n",
    "                del batch, out, prob\n",
    "                torch.cuda.empty_cache()\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "        # –°–æ–±–∏—Ä–∞–µ–º –º–∞—Å–∫—É\n",
    "        mask = np.zeros((H, W), dtype=np.float32)\n",
    "        count = np.zeros((H, W), dtype=np.float32)\n",
    "        for idx, (y, x) in enumerate(patch_coords):\n",
    "            patch_pred = preds[idx]\n",
    "            if patch_pred.ndim == 3:\n",
    "                patch_pred = patch_pred[0]\n",
    "            mask[y:y+patch_h, x:x+patch_w] += patch_pred\n",
    "            count[y:y+patch_h, x:x+patch_w] += 1\n",
    "        mask /= np.maximum(count, 1)\n",
    "        masks_dict[model_name] = (mask > threshold).astype(np.uint8)\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    del patch_batch, patch_tensors, patches\n",
    "    torch.cuda.empty_cache()\n",
    "    return masks_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result_column(img, mask, model_name='Model'):\n",
    "    plt.figure(figsize=(6, 12))\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{model_name}: Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title(\"Mask\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask, alpha=0.4, cmap='Reds')\n",
    "    plt.title(\"Overlay\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def show_multi_model_results(img, masks_dict):\n",
    "    n_models = len(masks_dict)\n",
    "    plt.figure(figsize=(4 * n_models, 12))\n",
    "    for col, (model_name, mask) in enumerate(masks_dict.items()):\n",
    "        # 1. Original\n",
    "        plt.subplot(3, n_models, 1 + col)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{model_name}\\nOriginal\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "        # 2. Mask\n",
    "        plt.subplot(3, n_models, 1 + n_models + col)\n",
    "        plt.imshow(mask, cmap=\"gray\")\n",
    "        plt.title(\"Mask\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "        # 3. Overlay\n",
    "        plt.subplot(3, n_models, 1 + 2*n_models + col)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(mask, cmap='Reds', alpha=0.4)\n",
    "        plt.title(\"Overlay\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def save_and_show_image(img, fname, title=None):\n",
    "    plt.figure(figsize=(min(16, img.shape[1]//32), 6))  # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª–∏–Ω–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    plt.imshow(img, cmap=None if img.ndim == 3 else 'gray')\n",
    "    if title: plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_and_save_results(img, mask, model_name, save_dir=\"./inference_results\", idx=0):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Original\n",
    "    fname_orig = os.path.join(save_dir, f\"{model_name}_orig_{idx}.png\")\n",
    "    save_and_show_image(img, fname_orig, title=f\"{model_name} Original\")\n",
    "    print(f\"Saved: {fname_orig}\")\n",
    "\n",
    "    # 2. Mask\n",
    "    fname_mask = os.path.join(save_dir, f\"{model_name}_mask_{idx}.png\")\n",
    "    save_and_show_image(mask, fname_mask, title=f\"{model_name} Mask\")\n",
    "    print(f\"Saved: {fname_mask}\")\n",
    "\n",
    "    # 3. Overlay\n",
    "    plt.figure(figsize=(min(16, img.shape[1]//32), 6))\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask, alpha=0.4, cmap='Reds')\n",
    "    plt.title(f\"{model_name} Overlay\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    fname_overlay = os.path.join(save_dir, f\"{model_name}_overlay_{idx}.png\")\n",
    "    plt.savefig(fname_overlay, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "    print(f\"Saved: {fname_overlay}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess_albu = A.Compose([\n",
    "    A.Resize(PATCH_H, PATCH_W),  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥ —Ç–≤–æ–π —Ä–∞–∑–º–µ—Ä\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "def preprocess_patch(patch):\n",
    "    return preprocess_albu(image=patch)['image']\n",
    "\n",
    "# --- –í—ã–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---\n",
    "IMG_DIR = Path('./aitex_data/extracted/Defect_images')\n",
    "img_files = sorted(list(IMG_DIR.glob('*.png')))\n",
    "img_path = img_files[0]\n",
    "\n",
    "img = cv2.imread(str(img_path))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# --- –ò–Ω—Ñ–µ—Ä–µ–Ω—Å ---\n",
    "result_masks = infer_full_image_with_models(\n",
    "    img,\n",
    "    models_dict=MODELS,\n",
    "    preprocess=preprocess_patch,\n",
    "    patch_h=PATCH_H,\n",
    "    patch_w=PATCH_W,\n",
    "    stride_h=STRIDE_H,\n",
    "    stride_w=STRIDE_W,\n",
    "    device=device,\n",
    "    config=CONFIG\n",
    ")\n",
    "\n",
    "for i, (model_name, mask) in enumerate(result_masks.items()):\n",
    "    visualize_and_save_results(img, mask, model_name, save_dir=\"./inference_results\", idx=i)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
